{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZBTJY39Bqi9"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"./fs_logo.png\">\n",
    "\n",
    "##  Lab 06 - Adversarial Deep Learning\n",
    "\n",
    "Seminar Künstliche Intelligenz, Frankfurt School, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSFSdKo2Bqi_"
   },
   "source": [
    "Die Analysen des Seminars **Künstliche Intelligenz** des Zertifikatstudiengangs **Certified Audit Data Scientist (CADS)** basieren auf Jupyter Notebook. Anhand solcher Notebooks ist es möglich eine Vielzahl von Datenanalysen und statistischen Validierungen durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./lab_06_banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im letzten Lab haben Sie die verschiedenen Elemente eines Supervised Deep Learning Workflow kennengelernt z.B. Datenaufbereitung, Modell Training und Modell Validierung. In diesem fünften Lab werden wir Jupyter Notebook verwenden, um ein erstes **Deep Learning basiertes Audit-Analyseverfahren** zu implementieren und anzuwenden.\n",
    "\n",
    "Hierzu werden wir die im Seminar vorgestellten Deep Autoencoder Neural Networks (AENNs) anwenden um Anomalien im Buchungsstoff einer Finanzbuchhaltung zu detektieren. Im Gegensatz zu klassischen Feedforward-Netzen lernen AENNs, die Eingabedaten in eine niedrig-dimensionale Repräsentation zu **encodieren**.  Gleichzeitig lernt das AENN, die ursprünglichen Daten wieder aus der enkodierten Repräsentation zu **dekodieren**. \n",
    "\n",
    "Die dekodierten Daten, die in der Regel als **Rekonstruktion** bezeichnet werden, sollten eine grosse Ähnlichkeit zu den ursprünglichen **Eingabedaten** aufweisen. Die Buchungssätze, für welche eine erfolgreiche Rekonstruktion nur fehlerhaft gelingt müssen deshalb eine oder mehrere ungewöhnliche Eigenschaften aufweisen. Die nachstehende Abbildung zeigt einen Überblick über den Deep Learning Prozess bzw. die AENN Netzarchitektur, welche wir in diesem Lab implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"./process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Rahmen des Lab werden wir wieder einige Funktionen der `PyTorch` Bibliothek nutzen, um das AENN zu implementieren und zu trainieren. Im Laufe des Trainingsprozess soll das AENN die charakteristische Eigenschaften historischer **Buchungen** bzw. **Journal Entries** lernen. Nach erfolgreichen Modelltraining, werden wir das Modell anwenden, um anhand des Rekonstruktionsfehlers ungewöhnliche Buchungen innerhalb des Datensatzes zu detektieren. Abschliessend werden wir die gelernten **Repräsentationen** der einzelnen Journaleinträge dazu verwenden, um die erhaltenen Ergebnisse noch aussagekräftiger zu interpretieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei etwaigen Fragen wenden Sie sich, wie immer gerne an uns via **marco (dot) schreyer (at) unisg (dot) ch**. Wir wünschen Ihnen Viel Freude mit unseren Notebooks und Ihren revisorischen Analysen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernziele des Labs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der heutigen Übung sollten Sie in der Lage sein:\n",
    "\n",
    ">1. Die **Grundkonzepte, Funktionsweise und Bestandteile** von Autoencoder Neuronalen Netzen zu verstehen.\n",
    ">2. Eine **Vorverarbeitung** von kategorischen Finanzdaten (d.h. One-Hot Encoding und Min-Max Normalisierung) durchzuführen. \n",
    ">3. Autoencoder Neuronalen Netze anzuwenden, um **Anomalien** in umfangreichen Finanzdaten aufzuspüren.\n",
    ">4. Die **Ergebnisse** bzw. den Rekonstruktionsfehler von Autoencoder Neuronalen Netzen zu interpretieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einrichten der Analyseumgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie in den vorangegangenen Übungen werden wir zunächst eine Reihe von Python-Bibliotheken importieren, welche die Datenanalyse und -visualisierung ermöglichen. In dieser Übung werden wir die Bibliotheken `PyTorch`, `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` und `Seaborn` verwenden. Nachfolgend importieren wir die benötigten Bibliotheken durch die Ausführung der folgenden Anweisungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python data science and utility libraries\n",
    "import os, sys, itertools, urllib, io, warnings\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import der `PyTorch` Deep Learning Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import der `Matplotlib` und `Seaborn` Visualisierungs Bibliotheken und setzen der Visualisierungsparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.rcParams['figure.dpi']= 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausschalten möglicher Warnmeldungen z.B. aufgrund von zukünftigen Änderungen der Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the warning filter flag to ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktivieren der sog. Inline-Darstellung von Visualisierungen in Jupyter-Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importieren der `Colab GDrive` Bibliothek und einbinden unseres `GDrive` Laufwerks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen von Unterverzeichnissen innerhalb des aktuellen Arbeitsverzeichnisses für (1) die `GDrive` Notebooks im Allgemeinen, (2) das Speichern der Originaldaten, (3) der Analyseergebnisse und (4) der trainierten Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Colab Notebooks directory\n",
    "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
    "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
    "\n",
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/01_data'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    "# create results sub-directory inside the Colab Notebooks directory\n",
    "results_directory = '/content/drive/MyDrive/Colab Notebooks/02_results'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/content/drive/MyDrive/Colab Notebooks/03_models'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Festlegen eines zufälligen Seeds zur Gewährleistung der Reproduzierbarkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value); # set pytorch seed cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktivieren des GPU Computing, durch setzen des `device` flag und setzen eines zufälligen `CUDA` Seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# set pytorch gpu seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] notebook with {} computation enabled'.format(str(now), str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige der Hardware Informationen zu den ggf. verfügbaren GPU(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige der Software Informationen über die verfügbaren `Python` bzw. `PyTorch` Versionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current Python version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The Python version: {}'.format(now, sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current PyTorch version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenakquise und Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heutzutage beschleunigen Unternehmen die Digitalisierung von Geschäftsprozessen, wovon auch Enterprise Resource Planning (ERP)-Systeme betroffen sind. Diese Systeme sammeln grosse Mengen Daten auf granularer Ebene. Dies gilt insbesondere für die Journalbuchungen einer Organisation, die innerhalb des Hauptbuch und den jeweiligen Nebenbüchern erfasst werden.\n",
    "\n",
    "Die Darstellung in **Abbildung 1** zeigt eine hierarchische Ansicht eines ERP-Systems, das Journalbuchungen in Datenbanktabellen erfasst. Im Kontext revisorischer Prüfungen können die in solchen Systemen erfassten Daten Spuren bzw. wertvolle Hinweise auf mögliche dolose Handlungen enthalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"./accounting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abbildung 1:** Hierarchische Ansicht eines Enterprise Resource Planning (ERP)-Systems, das Geschäftsvorfälle auf verschiedene Abstraktionsebenen in Datenbanktabellen erfasst, d.h. auf Ebene (1) des Geschäftsprozesses, (2) der Buchhaltung sowie (3) der Datenbank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden wir den im Rahmen des Labs verwendeten Datensatzes deskriptiv analysieren. Anschliessend werden wir die Daten vorverarbeiten um eine Ausgangslage für das Training eines Neuronalen Netzes zu schaffen. Der Lab Datensatz basiert auf einer angepassten Teilmenge des **\"Synthetic Financial Dataset For Fraud Detection \"** Datensatz von Lopez-Rojas. Der Originaldatensatz wurde ursprünglich über die Kaggle-Plattform für Data Science Wettbewerbe veröffentlicht und kann über den nachfolgenden Link abgerufen werden kann: https://www.kaggle.com/ntnu-testimon/paysim1.\n",
    "\n",
    "In einem ersten Schritt laden wir den Datensatz in unsere Analyseumgebung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into the notebook\n",
    "url = 'https://raw.githubusercontent.com/GitiHubi/CADS/main/lab_06/fraud_dataset_v2.csv'\n",
    "ori_dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend prüfen wir die Dimensionalität des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the datasets dimensionalities\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] transactional dataset of {} rows and {} columns retreived.'.format(now, ori_dataset.shape[0], ori_dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darüber hinaus speichern wir eine Sicherheitskopie des geladenen Datensatzes mit aktuellem Zeitstempel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine current timestamp \n",
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# define dataset filename \n",
    "filename = timestamp + \" - original_fraud_dataset.xlsx\"\n",
    "\n",
    "# save dataset extract to the data directory\n",
    "ori_dataset.head(1000).to_excel(os.path.join(data_directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initiales Daten Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält insgesamt **sieben kategorische** und **zwei numerische Attribute**, welche den innerhalb eines SAP FICO Moduls enthaltenen Tabellen BKPF (Buchungsbelegköpfe) und BSEG (Buchungsbelegsegmente) entsprechen. Die nachstehende Liste enthält einen Überblick über die einzelnen Attribute sowie eine kurze Beschreibung ihrer jeweiligen Semantik:\n",
    "\n",
    ">- `BELNR`: die Nummer des Buchhaltungsbelegs,\n",
    ">- `BUKRS`: der Buchungskreis\n",
    ">- `BSCHL`: der Buchungsschlüssel,\n",
    ">- `HKONT`: das gebuchte Hauptbuchkonto,\n",
    ">- `PRCTR`: das gebuchte Profit Center,\n",
    ">- `WAERS`: der Währungsschlüssel,\n",
    ">- `KTOSL`: der Schlüssel des Hauptbuchkontos,\n",
    ">- `DMBTR`: der Betrag in der Hauswährung,\n",
    ">- `WRBTR`: der Betrag in der Belegwährung.\n",
    "\n",
    "Sehen wir uns auch einmal die ersten 10 Zeilen des Datensatzes im Detail an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect top rows of dataset\n",
    "ori_dataset.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vielleicht ist Ihnen bei der Durchsicht der Attribute auch das Attribut mit der Bezeichung `Label` in den Daten aufgefallen. Dieses Attribut enthält die **Ground-Truth Informationen** zu den jeweils einzelnen Buchungen. Das Attribut beschreibt die 'wahre Natur' jeder Transaktion, d.h. ob es sich um eine **reguläre** Transaktion (gekennzeichnet durch `regulär`) oder eine **Anomalie** (gekennzeichnet durch `global` und `lokal`) handelt.  \n",
    "\n",
    "Innerhalb unseres Vorgehens werden wir die Label Information nur dazu verwenden, um die Ergebnisse unserer trainierten Modelle zu validieren. Bitte beachten Sie jedoch, dass uns eine solches Feld in der Realität oftmals nicht zur Verfügung steht. Schauen wir uns nun einmal die Verteilung der regulären gegenüber den anomalen Buchungen im Datensatz an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of anomalies vs. regular transactions\n",
    "ori_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse zeigt, dass wir es, ähnlich wie in der realen Welt, mit einem **unbalanzierten Datensatz** konfrontiert sind. D.h. insgesamg enthält der Datensatz nur einen sehr kleinen Anteil von **100 (0,109 %)** anomalen Transaktionen. Unter den 100 Anomalien befinden sich **70 (0,076 %)** *globale* Anomalien und **30 (0,003 %)** *lokale* Anomalien. \n",
    "\n",
    "In einem nächsten Schritt entfernen wir das `label` Attribut aus dem Trainingsdatensatz und speichern es in einer gesonderten Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \"ground-truth\" label information for the following steps of the class\n",
    "label = ori_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Vorverarbeitung der Kategorischen Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Sichtung der Daten geht hervor, dass die Mehrzahl der Attribute kategorische (diskrete) Attributwerte aufweisen, z.B. das Buchungsdatum, das Hauptbuchkonto, die Buchungsart und die Währung. Schauen wir uns nun die Verteilung der kategorischen Attribute *Buchungsschlüssel* `BSCHL` sowie *Hauptbuchkonto* `HKONT` einmal im Detail an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to plot posting key and general ledger account side by side\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot the distribution of the posting key attribute\n",
    "plot = sns.countplot(x=ori_dataset['BSCHL'], ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90)\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Buchungsschlüssel Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot the distribution of the general ledger attribute\n",
    "plot = sns.countplot(x=ori_dataset['HKONT'], ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90)\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Hauptbuchkonto Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Allgemeinen sind Neuronale Netze dafür konzipiert numerische Daten zu verarbeiten. Eine Möglichkeit, diese Anforderung zu erfüllen, ist die Anwendung eines Verfahrens, das als sog. **One-Hot Kodierung** bezeichnet wird. Hierdurch kann eine numerische Darstellung kategorischer Attributwerte abgeleitet werden. Bei der **One-Hot Kodierung** wird für jeden kategorischen Attributwert eine zusätzliche binäre Spalte in den Daten erstellt. \n",
    "\n",
    "Schauen wir uns hierzu das Beispiel in **Abbildung 2** unten an. Das kategorische Attribut **Receiver** in den Orginaldaten enthält die Namen 'Sally', 'John' und 'Emma'. Wir kodieren das Attribut als 'one-hot' Attribut, indem wir eine zusätzliche binäre Spalte für jeden kategorischen Wert in der Spalte 'Receiver' erstellen. Anschliessend kodieren wir z.B. jede Transaktion, die den Wert 'Sally' in der Spalte 'Receiver' aufweist mit dem Wert 1.0 innerhalb der 'Sally' Spalte der Transaktion. Sollte eine Transaktion einen anderen Wert in der Spalte 'Receiver' aufweisen, kodieren wir die 'Sally' Spalte mit dem Wert 0.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 500px; height: auto\" src=\"./encoding.png\">\n",
    "\n",
    "**Abbildung 2:** Beispielhafte 'One-Hot' Kodierung der verschiedenen Receiver Attributwerte in spezifische binäre 'One-Hot' Spalten. Dabei resultiert jeder im Datensatz beobachtbare Attributwert in einer eigene Spalte. Der Spaltenwert **1.0** kodiert das Vorkommen des Attributwertes in der entsprechenden Buchung. Der Spaltenwert **0.0** hingegen zeigt, dass der Attributwert nicht innerhalb der entsprechenden Buchung vorkommt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand dieses Verfahrens können die insgesamt sechs kategorischen Attribute des Datensatzes in numerische Attribute überführt werden. Die `Pandas` Bibliothek stellt hierzu die entsprechende Funktionalität zur Verfügung, welche wir im Nachfolgenden anwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical attributes to be \"one-hot\" encoded\n",
    "categorical_attr_names = ['BUKRS', 'KTOSL', 'PRCTR', 'BSCHL', 'HKONT', 'WAERS']\n",
    "\n",
    "# encode categorical attributes into a binary one-hot encoded representation \n",
    "ori_dataset_cat_processed = pd.get_dummies(ori_dataset[categorical_attr_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend überprüfen wie die vorgenommene **One-Hot Kodierung** anhand der 10 ersten Buchungen des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect encoded sample transactions\n",
    "ori_dataset_cat_processed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vorverarbeitung der numerischen Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend Analysieren wir nun die Verteilungen der **beiden numerischen Attribute** des Datensatzes. Hierbei handelt es sich um die Attribute (1) *Betrag in Hauswährung* `DMBTR` und (2) *Betrag in Dokumentwährung* `WRBTR` deren jeweilge Verteilungen wir nachfolgend visualisieren: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the log-scaled 'DMBTR' as well as the 'WRBTR' attribute value distribution\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "plot = sns.distplot(ori_dataset['DMBTR'].tolist(), ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Hauswährung - Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "plot = sns.distplot(ori_dataset['WRBTR'].tolist(), ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Dokumentwährung - Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Werte beider Betragsattribute weisen eine jeweils **schiefe** und **steile** Verteilung auf. Wir skalieren deshalb die Werte zunächst logarithmisch. Anschliessend min-max normalisieren wir die Skalierten Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the 'DMBTR' and 'WRBTR' attribute\n",
    "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_dataset[numeric_attr_names] + 1e-7\n",
    "\n",
    "# log scale the 'DMBTR' and 'WRBTR' attribute values\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attributes to the range [0,1]\n",
    "ori_dataset_num_processed = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt visualisieren wir die Verteilungen der skalierten bzw. normierten Werte beider Betragsattribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the log-scaled 'DMBTR' as well as the 'WRBTR' attribute value distribution\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "plot = sns.distplot(ori_dataset_num_processed['DMBTR'].tolist(), ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Hauswährung - Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "plot = sns.distplot(ori_dataset_num_processed['WRBTR'].tolist(), ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Dokumentwährung - Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merge Categorical and Numerical Transaction Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschliessend fügen wir die beiden vorverarbeiteten numerischen und kategorischen Attribute zu einem **einzigen Datensatz** zusammen. Der zusammengeführte Datensatz bildet die Grundlage für das nachfolgende Training des Deep Autoencoder Neural Networks (AENNs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_dataset_cat_processed, ori_dataset_num_processed], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werfen wir nun abschliessend noch einen finalen einen Blick auf die Dimensionalität des zusammengefügten Datensatzes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Abschluss der Vorverarbeitungsschritte verfügen wir über einen Datensatz, der aus einer Gesamtzahl von **91.147 Datensätzen** (Zeilen) und **618 Attributen** (Spalten) besteht. Wir behalten die Anzahl der Spalten im Hinterkopf, da sie die Dimensionalität der Eingabe- und Ausgabeschicht unseres AENNs bestimmen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INucYTG6BqjA"
   },
   "source": [
    "### 1.1 Python Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "py19ioTOBqjB"
   },
   "outputs": [],
   "source": [
    "# importing python utility libraries\n",
    "import os, sys, random, io, urllib\n",
    "from datetime import datetime\n",
    "\n",
    "# importing pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "\n",
    "# importing python plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vKomkqUYBqjJ"
   },
   "source": [
    "### 1.2 CUDNN and GPU Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PV_ZMka2BqjJ"
   },
   "source": [
    "To determine if CDNN is available on the server let's execute the cell below to display information about the available CUDNN version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NJ6fTEkbBqjK",
    "outputId": "5e751acf-3ae9-4fcf-e146-486ed8cbc189"
   },
   "outputs": [],
   "source": [
    "# print CUDNN backend version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] The CUDNN backend version: {}'.format(now, torch.backends.cudnn.version()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJeKij13BqjP"
   },
   "source": [
    "Also, let's display information about the potential GPUs running on the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "tO_Lb5jtBqjP",
    "outputId": "87671a0e-71c6-41e5-bf87-020c471f9705"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaV5pvlXBqjR"
   },
   "source": [
    "If CUDNN and GPU's are available let's still specify if we want to use both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-M08ndlBqjR"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTvXHK_GBqjT"
   },
   "source": [
    "### 1.3 Python and PyTorch Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-m1LNfNBqjT"
   },
   "source": [
    "Let's execute the cell below to display information about the Python and PyTorch version running on the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QviMLpbmBqjT",
    "outputId": "b28ce8d6-8321-428e-94bf-ecf510d8ba64"
   },
   "outputs": [],
   "source": [
    "# print current Python version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] The Python version: {}'.format(now, sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t-cF1m3tBqjU",
    "outputId": "b0b318e1-a7e2-4563-de11-94ad9d2ff418"
   },
   "outputs": [],
   "source": [
    "# print current PyTorch version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] The PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajGqTkoZBqjV"
   },
   "source": [
    "### 1.4 Random Seed Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVCIe8u8BqjW"
   },
   "source": [
    "Finally, let' set the seeds of random elements in the code e.g. the initialization of the network parameters to guarantee deterministic computation and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdSSdufWBqjW"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "rd.seed(seed_value) # set random seed\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    torch.cuda.manual_seed(seed_value) # set pytorch seed GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doOhKiQYBqjX"
   },
   "source": [
    "### 1.5 Folder Structure Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mepggmaoBqjY"
   },
   "source": [
    "Create notebook structure to store the data as well as the trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoGtpKsbBqjY"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'): os.makedirs('./data')  # create data directory\n",
    "if not os.path.exists('./models'): os.makedirs('./models')  # create trained models directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUU-P-hsBqjZ"
   },
   "source": [
    "## 2. Financial Fraud Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeQh4PP-BqjZ"
   },
   "source": [
    "In this section, we will conduct a descriptive analysis of the financial dataset. Furthermore, we will apply some necessary pre-processing steps to train a deep neural network. The dataset is based on a derivation of the **\"Synthetic Financial Dataset For Fraud Detection\"** by Lopez-Rojas [6] available via the Kaggle predictive modelling and analytics competitions platform that can be obtained using the following link: https://www.kaggle.com/ntnu-testimon/paysim1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiqmYgDiBqjZ"
   },
   "outputs": [],
   "source": [
    "# load the synthetic ERP dataset\n",
    "#ori_dataset = pd.read_csv('./data/fraud_dataset_v2.csv')\n",
    "\n",
    "# load the synthetic ERP dataset\n",
    "url = 'https://raw.githubusercontent.com/GitiHubi/deepAI/master/data/fraud_dataset_v2.csv'\n",
    "ori_dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIsyJ-IBBqja"
   },
   "source": [
    "Let's now inspect the dataset dimensions in terms of the number of journal entries and number of attributes contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nuCBOE3WBqja",
    "outputId": "ec65b2e7-364e-484d-ec44-64f58d62c5aa"
   },
   "outputs": [],
   "source": [
    "# inspect the dataset dimensions\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] Transactional dataset of {} rows and {} columns loaded'.format(now, ori_dataset.shape[0], ori_dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5lhkqaBBqjb"
   },
   "source": [
    "### 2.1 Initial Data and Attribute Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NR6P7wLNBqjb"
   },
   "source": [
    "We augmented the dataset and renamed the attributes to appear more similar to a real-world dataset that one usually observes in SAP-ERP systems as part of SAP's Finance and Cost controlling (FICO) module. \n",
    "\n",
    "The dataset contains a subset of in total 7 categorical and 2 numerical attributes available in the FICO BKPF (containing the posted journal entry headers) and BSEG (containing the posted journal entry segments) tables. Please, find below a list of the individual attributes as well as a brief description of their respective semantics:\n",
    "\n",
    ">- `BELNR`: the accounting document number,\n",
    ">- `BUKRS`: the company code,\n",
    ">- `BSCHL`: the posting key,\n",
    ">- `HKONT`: the posted general ledger account,\n",
    ">- `PRCTR`: the posted profit center,\n",
    ">- `WAERS`: the currency key,\n",
    ">- `KTOSL`: the general ledger account key,\n",
    ">- `DMBTR`: the amount in local currency,\n",
    ">- `WRBTR`: the amount in document currency.\n",
    "\n",
    "Let's also have a closer look into the top 10 rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "sw6PiTg4Bqjb",
    "outputId": "21b41b8c-91bd-46fc-8b60-f348401b4a82"
   },
   "outputs": [],
   "source": [
    "# inspect top rows of the ERP dataset\n",
    "ori_dataset.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hl8Ee3urBqjc"
   },
   "source": [
    "You may also have noticed the attribute `label` in the data. We will use this field throughout the lab to evaluate the quality of our trained models. The field describes the true nature of each individual transaction of either being a **regular** transaction (denoted by `regular`) or an **anomaly** (denoted by `global` and `local`). Let's have closer look into the distribution of the regular vs. anomalous transactions in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "MdqhwiENBqjc",
    "outputId": "7a45eccc-a815-4a62-e295-e0a724989601"
   },
   "outputs": [],
   "source": [
    "# number of anomalies vs. regular transactions\n",
    "ori_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRHF8ncuBqjd"
   },
   "source": [
    "Ok, the statistic reveals that, similar to real world scenarios, we are facing a highly \"unbalanced\" dataset. Overall, the dataset contains only a small fraction of **100 (0.018%)** anomalous transactions. While the 100 anomalous entries encompass **70 (0.013%)** \"global\" anomalies and **30 (0.005%)** \"local\" anomalies as introduced in section 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBFw8UPaBqje"
   },
   "outputs": [],
   "source": [
    "# remove the \"ground-truth\" label information for the following steps of the lab\n",
    "label = ori_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84F8IimFBqjf"
   },
   "source": [
    "### 2.2 Pre-Processing of Categorical Transaction Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRCFChAUBqjf"
   },
   "source": [
    "From the initial data assessment above we can observe that the majority of attributes recorded in AIS- and ERP-systems contain categorical (discrete) attribute values, e.g. the posting date, the general-ledger account, the posting type, the currency. Let's visually inspect the distribution of two of the dataset attributes provided, namely (1) the posting key (technically denoted by `BSCHL`) as well as (2) the general ledger account (technically denoted by `HKONT`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "mj6CSUQWBqjf",
    "outputId": "e50430a9-eb70-466d-9b36-61bb0c1a8fa7"
   },
   "outputs": [],
   "source": [
    "# prepare to plot posting key and general ledger account side by side\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "# plot the distribution of the posting key attribute\n",
    "g = sns.countplot(x=ori_dataset.loc[label=='regular', 'BSCHL'], ax=ax[0])\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=0)\n",
    "g.set_title('Distribution of BSCHL attribute values')\n",
    "\n",
    "# plot the distribution of the general ledger account attribute\n",
    "g = sns.countplot(x=ori_dataset.loc[label=='regular', 'HKONT'], ax=ax[1])\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=0)\n",
    "g.set_title('Distribution of HKONT attribute values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0iJjCZgBqjg"
   },
   "source": [
    "Unfortunately, neural networks are in general not designed to be trained directly on categorical data and require the attributes to be trained on to be numeric. One simple way to meet this requirement is by applying a technique referred to as \"one-hot\" encoding. Using this encoding technique, we will derive a numerical representation of each of the categorical attribute values. One-hot encoding creates new binary columns for each categorical attribute value present in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsLtwgLABqjh"
   },
   "source": [
    "Let's work through a brief example: The categorical attribute “Receiver” below contains the names \"John\", \"Timur\" and \"Marco\". We \"one-hot\" encode the names by creating a separate binary column for each possible name value observable in the \"Receiver\" column. Now, we encode for each transaction that contains the value \"John\" in the \"Receiver\" column this observation with 1.0 in the newly created \"John\" column and 0.0 in all other created name columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUNcjTE8Bqjh"
   },
   "source": [
    "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"https://github.com/GitiHubi/deepAD/blob/master/images/encoding.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__cNdLAiBqji"
   },
   "source": [
    "Using this technique will \"one-hot\" encode the 6 categorical attributes in the original transactional dataset to obtain a binary (\"one-hot\" encoded) representation of each attribute. This can be achieved using the get_dummies() function available in the Pandas data science library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXXEzhToBqjj"
   },
   "outputs": [],
   "source": [
    "# select categorical attributes to be \"one-hot\" encoded\n",
    "categorical_attr_names = ['KTOSL', 'PRCTR', 'BSCHL', 'HKONT', 'BUKRS', 'WAERS']\n",
    "\n",
    "# encode categorical attributes into a binary one-hot encoded representation \n",
    "ori_dataset_categ_transformed = pd.get_dummies(ori_dataset[categorical_attr_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AkuFIvQBqjk"
   },
   "source": [
    "Finally, let's inspect the encoding of 10 sample transactions to see if we have been successfull:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "3thCijNZBqjk",
    "outputId": "6072ac73-7db7-4b84-9c1a-9e0e27cf9cce"
   },
   "outputs": [],
   "source": [
    "# inspect encoded sample transactions\n",
    "ori_dataset_categ_transformed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d70RoaUjBqjl"
   },
   "source": [
    "### 2.2 Pre-Processing of Numerical Transaction Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsBwOxDABqjl"
   },
   "source": [
    "Let's now inspect the distributions of the two numerical attributes contained in the transactional dataset namely, the (1) local currency amount DMBTR and the (2) document currency amount WRBTR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "zLEXn828Bqjl",
    "outputId": "45613858-1b72-4919-da19-e8869378e93f"
   },
   "outputs": [],
   "source": [
    "# init the plots\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset['DMBTR'].tolist(), ax=ax[0])\n",
    "g.set_title('Distribution of DMBTR amount values')\n",
    "\n",
    "# set axis-labels \n",
    "ax[0].set_xlabel('DMBTR')\n",
    "ax[0].set_ylabel('density')\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "g = sns.distplot(ori_dataset['WRBTR'].tolist(), ax=ax[1])\n",
    "g.set_title('Distribution of WRBTR amount values')\n",
    "\n",
    "# set axis-labels\n",
    "ax[1].set_xlabel('WRBTR')\n",
    "ax[1].set_ylabel('density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvn5CYtXBqjm"
   },
   "source": [
    "As expected, it can be observed, that for both attributes the distributions of amount values are skewed and encompass a heavy tailed distribution. In order to faster approach a potential global minimum it is good practice to scale and normalize numerical input values prior to network training. Therefore, we first log-scale both variables and second min-max normalize the scaled amounts to the interval [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeUp3ppdBqjn"
   },
   "outputs": [],
   "source": [
    "# select \"DMBTR\" vs. \"WRBTR\" attribute\n",
    "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_dataset[numeric_attr_names] + 1e-4\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attributes to the range [0,1]\n",
    "ori_dataset_numeric_attr = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-FWCgHmBqjo"
   },
   "source": [
    "Let's now visualize the log-scaled and min-max normalized distributions of both attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "TJZQ5oCUBqjp",
    "outputId": "821dee60-3602-4820-8b51-04408fda0b13"
   },
   "outputs": [],
   "source": [
    "# init the plots\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset_numeric_attr['DMBTR'].tolist(), ax=ax[0])\n",
    "g.set_title('Distribution of scaled DMBTR amount values')\n",
    "\n",
    "# set axis-labels \n",
    "ax[0].set_xlabel('DMBTR')\n",
    "ax[0].set_ylabel('density')\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset_numeric_attr['WRBTR'].tolist(), ax=ax[1])\n",
    "g.set_title('Distribution of scaled WRBTR amount values')\n",
    "\n",
    "# set axis-labels\n",
    "ax[1].set_xlabel('WRBTR')\n",
    "ax[1].set_ylabel('density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3f1-gnR3Bqjp"
   },
   "source": [
    "Ok, let's now visually investigate the scaled distributions of both attributes in terms of the distinct anomaly classes contained in the population of journal entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "PrKpgWQ6Bqjp",
    "outputId": "4e08325e-16ba-4909-b944-88970c5eb869"
   },
   "outputs": [],
   "source": [
    "# append 'label' attribute \n",
    "numeric_attr_vis = ori_dataset_numeric_attr.copy()\n",
    "numeric_attr_vis['label'] = label\n",
    "\n",
    "# plot the log-scaled and min-max normalized numeric attributes\n",
    "g = sns.pairplot(data=numeric_attr_vis, vars=numeric_attr_names, hue='label', palette={'regular': 'C0', 'local': 'C3', 'global': 'C1'}, markers=['o', 'x', 'x'])\n",
    "\n",
    "# set figure title\n",
    "g.fig.suptitle('Distribution of DMBTR vs. WRBTR amount values', y=1.02)\n",
    "\n",
    "# set figure size\n",
    "g.fig.set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buHTeGiLBqjq"
   },
   "source": [
    "Ok, as anticipated the numeric attribute values of the \"global\" anomalies (orange) fall outside the range of the regular amount distributions due to their unusual high amount values. In contrast, the numeric attribute values of the \"local\" anomalies (red) are much more commingled within the regular transaction amounts.\n",
    "As DMBTR attribute contains a number of extreme values we might want to visulalize its distribution by omitting those set of extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcppaffEBqjq"
   },
   "source": [
    "### 2.3 Merge Categorical and Numerical Transaction Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGDMP20iBqjq"
   },
   "source": [
    "Finally, we merge both pre-processed numerical and categorical attributes into a single dataset that we will use for training our deep autoencoder neural network (explained an implemented in the following section 4.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWOWVEs0Bqjr"
   },
   "outputs": [],
   "source": [
    "# merge categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_dataset_categ_transformed, ori_dataset_numeric_attr], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r17XX6QdBqjr"
   },
   "source": [
    "Now, let's again have a look at the dimensionality of the dataset after we applied the distinct pre-processing steps to the attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "t-VRrGxqBqjr",
    "outputId": "e6246df6-eb12-4aed-cb0b-9b4a81e1661d"
   },
   "outputs": [],
   "source": [
    "# inspect final dimensions of pre-processed transactional data\n",
    "ori_subset_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2m84np1Bqjs"
   },
   "source": [
    "Ok, upon completion of all the pre-processing steps (incl. the exercises) we should end up with an encoded dataset consisting of a total number of 533,009 records (rows) and **618 encoded attributes** (columns). Let's keep the number number of columns in mind since it will define the dimensionality of the input- and output-layer of our deep autoencoder network which we will now implement in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQD5144JBqjs"
   },
   "source": [
    "## 3. Adversarial Autoencoder Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vu8jws-WBqjs"
   },
   "source": [
    "The Adversarial Autoencoder Neural Network (AAE) architecture, as illustrated in the figure below, extends the concept\n",
    "of Autoencoder Neural Networks (AE) by imposing an arbitrary prior on the AEs latent space using a GAN training setup. This is achieved by training the AAE jointly in two phases (1) a reconstruction phase as well as (2) an adversarial regularization phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAMjNjsvBqjt"
   },
   "source": [
    "In the reconstruction phase, the AAEs encoder network $q_{\\theta}(z|x)$ is trained to learn an aggregated posterior distribution $q(z)$ of the journal entries $X$ over the latent code vector $Z$. Thereby, the learned posterior distribution corresponds to a compressed representation of the journal entry characteristics. Similarly to AENs, the decoder\n",
    "network $p_{\\theta}(\\hat{x}|z)$ of the AAE utilizes the learned latent code vector representations $Z$ to reconstruct the journal entries $\\hat{X}$ as faithfully as possible to minimize the AAEs reconstruction error.\n",
    "\n",
    "In the regularization phase, an adversarial training setup is applied were the encoder network $q_{\\theta}(z|x)$ of the AAE functions as the generator network. In addition, a discriminator network $d_{\\theta}(z)$ is attached on top of the learned latent code vector $Z$. Similarly to GANs, the discriminator network of the AAE is trained to distinguish samples of an imposed prior distribution $p(z)$ onto $Z$ from the learned aggregated posterior distribution $q(z)$. In contrast, the encoder network is trained to learn a posterior distribution $p(z) ≈ q(z)$ that fools the discriminator network into thinking that the samples drawn from $q(z)$ originate from the imposed prior distribution $p(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BI7zJu4Bqjt"
   },
   "source": [
    "<img align=\"middle\" style=\"max-width: 830px; height: auto\" src=\"https://github.com/GitiHubi/deepAD/blob/master/images/autoencoder_2.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmPCygUqBqjt"
   },
   "source": [
    "### 3.1 AAE Implementation - Encoder / Generator Network $q_{\\theta}(z|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5DMIOWUBqjt"
   },
   "source": [
    "Now, let's start implementing an AAE by first implementing the encoder-generator network $q_{\\theta}(z|x)$ using PyTorch. For the encoder-generator, we aim to implement a network consisting of **five fully-connected layers**. Furthermore, the encoder-generator is specified by the following number of neurons per layer: \"618-256-64-16-4-2\". Meaning the first layer consists of 618 neurons (specified by the dimensionality of our input data), the second layer of 256 neurons and the subsequent layers of 64, 16, 4 and 2 neurons respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hY5356SWBqjt"
   },
   "source": [
    "Some elements of the encoder network code below should be given particular attention:\n",
    "\n",
    ">- `self.encoder_Lx`: defines the linear transformation of the layer applied to the incoming input: $Wx + b$.\n",
    ">- `nn.init.xavier_uniform`: inits the layer weights using a uniform distribution according to [9].\n",
    ">- `nn.init.constant`: inits the layer bias with a constant value of 0.0. \n",
    ">- `self.encoder_Rx`: defines the non-linear transformation of the layer: $\\sigma(\\cdot)$.\n",
    "\n",
    "We use **\"Leaky ReLUs\"** as introduced by Xu et al. in [7] to avoid \"dying\" non-linearities and to speed up training convergence. Leaky ReLUs allow a small gradient even when a particular neuron is not active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_I8259HBqjt"
   },
   "outputs": [],
   "source": [
    "# define encoder class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # specify first layer - in 618, out 256\n",
    "        self.map_L1 = nn.Linear(input_size, hidden_size[0], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 256, out 64\n",
    "        self.map_L2 = nn.Linear(hidden_size[0], hidden_size[1], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 64, out 16\n",
    "        self.map_L3 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify fourth layer - in 16, out 4\n",
    "        self.map_L4 = nn.Linear(hidden_size[2], hidden_size[3], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_R4 = torch.nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify fifth layer - in 4, out 2\n",
    "        self.map_L5 = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L5.weight)\n",
    "        nn.init.constant_(self.map_L5.bias, 0.0)\n",
    "        self.map_R5 = torch.nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_R4(self.map_L4(x))\n",
    "        x = self.map_R5(self.map_L5(x))\n",
    "\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYt7sO8kBqju"
   },
   "source": [
    "Now, we are ready to instantiate the encoder-generator model to be trained on the CPU or to be trained on any of the available GPUs (if CUDNN is available and `USE_CUDA` is set to `True`) by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyTFqrqSBqju"
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "encoder_train = Encoder(input_size=ori_subset_transformed.shape[1], hidden_size=[256, 64, 16, 4, 2])\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    encoder_train = encoder_train.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nd1RHRnZBqjv"
   },
   "source": [
    "Once the model is initialized we can visualize the model structure and review the implemented network architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "mWXGUOsWBqjv",
    "outputId": "fb3d3686-7a9a-41d0-813a-723d0cd28bab"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] encoder-generator architecture:\\n\\n{}\\n'.format(now, encoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNFSruVMBqjv"
   },
   "source": [
    "Looks, great? Excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhC0QTXUBqjv"
   },
   "source": [
    "### 3.2 AAE Implementation - Decoder Network $p_{\\theta}(x|z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxsh9OvXBqjw"
   },
   "source": [
    "Let's continue the AAE by implementing the corresponding decoder network. The decoder also consists of five fully-connected layers. Furthermore, the decoder network is intended to **symmetrically mirror** the encoder networks architecture by a layer wise inversion \"2-4-16-64-256\" of the encoder network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjnC8eTXBqjw"
   },
   "outputs": [],
   "source": [
    "# define decoder class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # specify first layer - in 2, out 4\n",
    "        self.map_L1 = nn.Linear(hidden_size[0], hidden_size[1], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 4, out 16\n",
    "        self.map_L2 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 16, out 64\n",
    "        self.map_L3 = nn.Linear(hidden_size[2], hidden_size[3], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify fourth layer - in 64, out 256\n",
    "        self.map_L4 = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        # specify fifth layer - in 256, out 618\n",
    "        self.map_L5 = nn.Linear(hidden_size[4], output_size, bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L5.weight)\n",
    "        nn.init.constant_(self.map_L5.bias, 0.0)\n",
    "        self.map_S5 = torch.nn.Sigmoid()\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_R4(self.map_L4(x))\n",
    "        x = self.map_S5(self.map_L5(x))\n",
    "\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxpHMkmnBqjw"
   },
   "source": [
    "Let's also instantiate the decoder model for CPU or GPU training and convince ourselves that it was successfully initialized by printing and reviewing its architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "dfME7m7fBqjw",
    "outputId": "df5e22ac-7eeb-43a2-e489-552db3f82d6a"
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "decoder_train = Decoder(output_size=ori_subset_transformed.shape[1], hidden_size=[2, 4, 16, 64, 256])\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    decoder_train = decoder_train.cuda()\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] decoder architecture:\\n\\n{}\\n'.format(now, decoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "962HA4IbBqjx"
   },
   "source": [
    "### 3.3 AAE Implementation - Discriminator Network $d_{\\theta}(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GO9ChOLBqjx"
   },
   "source": [
    "Let's, now as a final step, complete the AAE implementation by implementing the discriminator network $d_{\\theta}(z)$. The discriminator also consists of five fully-connected layers. Furthermore, the discriminator is specified by the following number of neurons per layer: \"256-16-4-2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xLZxg0hBqjx"
   },
   "outputs": [],
   "source": [
    "# define discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # specify first layer - in 2, out 256\n",
    "        self.map_L1 = nn.Linear(input_size, hidden_size[0], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 256, out 16\n",
    "        self.map_L2 = nn.Linear(hidden_size[0], hidden_size[1], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 16, out 4\n",
    "        self.map_L3 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        # specify fourth layer - in 4, out 2\n",
    "        self.map_L4 = nn.Linear(hidden_size[2], output_size, bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_S4 = torch.nn.Sigmoid()\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_S4(self.map_L4(x))\n",
    "\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR6urBPBBqjy"
   },
   "source": [
    "Let's also instantiate the discriminator model for CPU or GPU training and convince ourselves that it was successfully initialized by printing and reviewing its architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "C2ktcdrpBqjz",
    "outputId": "e63c0a1c-7793-4e2c-cbcc-e6a88f34fd73"
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "discriminator_train = Discriminator(input_size=2, hidden_size=[256, 16, 4, 2], output_size=1)\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    discriminator_train = discriminator_train.cuda()\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] discriminator architecture:\\n\\n{}\\n'.format(now, discriminator_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3jVSyWCVBqjz"
   },
   "source": [
    "### 3.4 Adversarial Autoencoder Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igoc5tVzBqjz"
   },
   "source": [
    "Now that we have implemented the AAE we are ready to train the network. Prior to starting the training, we need to define an appropriate loss functions, learning rates and parameter optimization techniques. Remember, we aim to train the adversarial autoencoder jointly in two training phases, namely (1) a reconstruction phase as well as (2) a regularization phase. In the following we will set the training parameters of each training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY6l5Ie3Bqjz"
   },
   "source": [
    "#### 3.4.1 Reconstruction Phase Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-nBtzeBqjz"
   },
   "source": [
    "In the reconstruction phase, the AAEs encoder network $q_{\\theta}(z|x)$ is trained to learn an aggregated posterior distribution $q(z)$ of the journal entries $X$ over the latent code vector $Z$. Thereby, the learned posterior distribution corresponds to a compressed representation of the journal entry characteristics. Similarly to AENs, the decoder network $p_{\\theta}(\\hat{x}|z)$ of the AAE utilizes the learned latent code vector representations $Z$ to reconstruct the journal entries $\\hat{X}$ as faithfully as possible to minimize the AAEs reconstruction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhuwT1qcBqj0"
   },
   "source": [
    "To achieve this optimization objective, we calculate (1) the **binary cross-entropy reconstruction error (BCE)** of the categorical attribute value encodings $x^{i}_{cat}$, e.g., the encoded general ledger account ids, and (2) the **mean-squared reconstruction error (MSE)** of the numerical attribute value encodings $x^{i}_{con}$, e.g., the encoded posting amount, as given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gih4aR78Bqj0"
   },
   "source": [
    "$\\mathcal{L}_{\\theta}^{REC}(x^{i};\\hat{x}^{i}) = \\gamma \\hspace{1mm} \\mathcal{L}^{CE}_{\\theta}(x^{i}_{cat};\\hat{x}^{i}_{cat}) + (1 - \\gamma) \\hspace{1mm} \\mathcal{L}^{MSE}_{\\theta}(x^{i}_{con};\\hat{x}^{i}_{con})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCYwmGUOBqj0"
   },
   "source": [
    "for a set of $n$-journal entries $x^{i}$, $i=1,...,n$ and their respective reconstructions $\\hat{x}^{i}$ and all journal entry attributes $j=1,...,k$. Luckily, an implementation of the BCE and MSE loss is already available in PyTorch. It can be instantiated \"off-the-shelf\" via execution of the following PyTorch commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLZkO1D1Bqj0"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "reconstruction_criterion_categorical = nn.BCELoss(reduction='mean')\n",
    "reconstruction_criterion_numeric = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    reconstruction_criterion_categorical = reconstruction_criterion_categorical.cuda()\n",
    "    reconstruction_criterion_numeric = reconstruction_criterion_numeric.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZnljTPUbBqj1"
   },
   "source": [
    "We will use the Adam optimization as proposed in [11] and set the learning-rate  l=0.001. Each mini-batch step the optimizer will update the encoder- and decoder-parameters $\\theta$ according to degree of reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJ7dte_JBqj1"
   },
   "outputs": [],
   "source": [
    "# define encoder and decoded learning rate\n",
    "learning_rate_enc = 1e-3\n",
    "learning_rate_dec = 1e-3\n",
    "\n",
    "# define encoder and decoder optimization strategy\n",
    "encoder_optimizer = optim.Adam(encoder_train.parameters(), lr=learning_rate_enc)\n",
    "decoder_optimizer = optim.Adam(decoder_train.parameters(), lr=learning_rate_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YnBKo9EBqj1"
   },
   "source": [
    "#### 3.4.2 Regularization Phase Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0TJJ6_cBqj1"
   },
   "source": [
    "In the regularization phase, an adversarial training setup is applied were the encoder network $q_{\\theta}(z|x)$ of the AAE functions as the generator network. In addition, a discriminator network $d_{\\phi}(z)$ is attached on top of the learned latent code vector $Z$. Similarly to GANs, the discriminator network of the AAE is trained to distinguish samples of an imposed prior distribution $p(z)$ onto $Z$ from the learned aggregated posterior distribution $q(z)$. In contrast, the encoder network is trained to learn a posterior distribution $p(z) \\approx q(z)$ that fools the discriminator network into thinking that the samples drawn from $q(z)$ originate from the imposed prior distribution $p(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvzmLhGnBqj1"
   },
   "source": [
    "To achieve this optimization objective, we calculate the **binary cross-entropy reconstruction error (BCE)**, as given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbijUiDQBqj1"
   },
   "outputs": [],
   "source": [
    "# init the discriminator losses\n",
    "discriminator_criterion = nn.BCELoss()\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    discriminator_criterion = discriminator_criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rjk_l79fBqj2"
   },
   "source": [
    "We will use the Adam optimization as proposed in [11] and set the learning-rate  l=0.00001. Each mini-batch step the optimizer will update the generator parameters $\\theta$ as well as the discriminator parameters $\\phi$ according to degree of discrimination error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6a1kOzS2Bqj3"
   },
   "outputs": [],
   "source": [
    "# define generator and discriminator learning rate\n",
    "learning_rate_dis_z = 1e-5\n",
    "\n",
    "# define generator and discriminator optimization strategy\n",
    "discriminator_optimizer = optim.Adam(discriminator_train.parameters(), lr=learning_rate_dis_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WnBg9kaBqj5"
   },
   "source": [
    "Now that we have successfully implemented and defined the three AAE building blocks let's take some time to review the `encoder-generator`, `decoder` and `discriminator` model definition as well as the loss. Please, read the above code and comments carefully and don't hesitate to let us know any questions you might have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-Cjxa-tBqj5"
   },
   "source": [
    "### 3.5 Creation of the Imposed Latent Prior Distribution $p(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IX4_QvngBqj5"
   },
   "source": [
    "In order to partition the journal entry representations learned by the AAE, we sample from a prior distribution $p(z)$ comprised of a mixture of $\\tau$ multivariate isotropic Gaussians $\\mathcal{N}(\\mu,\\mathcal{I})$, where $\\mu \\in \\mathcal{R}^{2}$. In the following example we create a prior distribution $p(z)$ consisting $\\tau=5$ isotropic Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMVs7_FvBqj5"
   },
   "outputs": [],
   "source": [
    "# define the number of gaussians\n",
    "tau = 5 \n",
    "\n",
    "# define radius of each gaussian\n",
    "radius = 0.8\n",
    "\n",
    "# define the sigma of each gaussian\n",
    "sigma = 0.01\n",
    "\n",
    "# define the dimensionality of each gaussian\n",
    "dim = 2\n",
    "\n",
    "# determine x and y coordinates of the target mixture of gaussians\n",
    "x_centroid = (radius * np.sin(np.linspace(0, 2 * np.pi, tau, endpoint=False)) + 1) / 2\n",
    "y_centroid = (radius * np.cos(np.linspace(0, 2 * np.pi, tau, endpoint=False)) + 1) / 2\n",
    "\n",
    "# determine each gaussians mean (centroid) and standard deviation\n",
    "mu_gauss = np.vstack([x_centroid, y_centroid]).T\n",
    "\n",
    "# determine the number of samples to be created per gaussian\n",
    "samples_per_gaussian = 100000\n",
    "\n",
    "# iterate over the number of distinct gaussians\n",
    "for i, mu in enumerate(mu_gauss):\n",
    "\n",
    "    # case: first gaussian\n",
    "    if i == 0:\n",
    "\n",
    "        # randomly sample from gaussion distribution \n",
    "        z_continous_samples_all = np.random.normal(mu, sigma, size=(samples_per_gaussian, dim))\n",
    "\n",
    "    # case: non-first gaussian\n",
    "    else:\n",
    "\n",
    "        # randomly sample from gaussian distribution\n",
    "        z_continous_samples = np.random.normal(mu, sigma, size=(samples_per_gaussian, dim))\n",
    "\n",
    "        # collect and stack new samples\n",
    "        z_continous_samples_all = np.vstack([z_continous_samples_all, z_continous_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fT0CgtXSBqj7"
   },
   "source": [
    "Let's visually inspect the generated prior distribution $p(z)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "FozilkQNBqj8",
    "outputId": "f44fbd9b-d585-408a-943a-33745de73bd6"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot reconstruction error scatter plot\n",
    "ax.scatter(z_continous_samples_all[:, 0], z_continous_samples_all[:, 1], c='C0', marker=\"o\", edgecolors='w', linewidth=0.5) \n",
    "ax.set_xlabel('$z_1$')\n",
    "ax.set_ylabel('$z_2$')\n",
    "\n",
    "# add plot title\n",
    "ax.set_title('Prior Latent Space Distribution $p(z)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aE1w_stCBqj8"
   },
   "source": [
    "Ok, great. Looks like anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAvFBlyeBqj8"
   },
   "source": [
    "## 4. Training the Adversarial Autoencoder Neural Network (AAE) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2KNFyqFBqj8"
   },
   "source": [
    "In this section, we will train our deep adversarial autoencoder neural network (as implemented in section 3. of the lab) using the encoded transactional data (created in section 2. of the lab) as well as the prior distribution (created in section 4. of the lab). More specifically, we will have a detailed look into the distinct training steps as well as how to monitor the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_NsNMmlBqj8"
   },
   "source": [
    "### 4.1 Preparing the Network Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-70bpc6Bqj9"
   },
   "source": [
    "Let's now start to train a corresponding model for **100 epochs** and a **mini-batch size of 128** journal entries per batch. This implies that the whole dataset will be fed to the AENN 5 times in chunks of 128 journal entries yielding to 4,165 mini-batches (533,009 journal entries / 128 journal entries per mini-batch) per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VXom63JBqj9"
   },
   "outputs": [],
   "source": [
    "# specify training parameters\n",
    "num_epochs = 10\n",
    "mini_batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFb5IZh-Bqj9"
   },
   "source": [
    "During the training phase, we will fetch the individual mini-batches of the entire population of journal entries. To achieve this, we will use PyTorch's `DataLoader` that provides single- or multi-process iterators over a given dataset to load one mini-batch at a time. By enabling `shuffle=True` the data will be reshuffled at every epoch prior to feeding it to the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNeHachtBqj9"
   },
   "outputs": [],
   "source": [
    "# convert pre-processed data to pytorch tensor\n",
    "torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()\n",
    "\n",
    "# convert to pytorch tensor - none cuda enabled\n",
    "dataloader = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=True, num_workers=0)\n",
    "# note: we set num_workers to zero to retrieve deterministic results\n",
    "\n",
    "# determine if CUDA is available at compute node\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    dataloader = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fpSkBadBqj-"
   },
   "source": [
    "### 4.2 Running the Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XebdkhVBqj-"
   },
   "source": [
    "Finally, we start training the model. The training procedure of each mini-batch is performed in two phases, namely a (1) reconstruction phase and (2) regularization phase. The distinct training steps conducted during the reconstruction phase are the following:\n",
    "\n",
    ">1. do a journal entry batch forward pass through the encoder-decoder networks,\n",
    ">2. compute the combined reconstruction loss $\\mathcal{L}_{\\theta}^{REC}(x^{i};\\hat{x}^{i})$, \n",
    ">3. do a backward pass through the encoder-decoder part, and,\n",
    ">4. update the parameters of the encoder $q_\\theta(\\cdot)$ and decoder $p_\\theta(\\cdot)$ networks.\n",
    "\n",
    "The distinct training steps conducted during the regularization phase are the following (discriminator training):\n",
    "\n",
    ">1. do a journal entry batch forward pass through the generator network to obtain representation $z^{i}_{fake} \\sim q_\\theta(\\cdot)$,\n",
    ">2. sample representation from the imposed mixture of Gaussians prior distribution $z^{i}_{real} \\sim p(\\cdot)$,\n",
    ">3. compute the discrimination loss $\\mathcal{L}_{\\theta}^{DIS}(z^{i}_{fake}; z^{i}_{real})$, and,\n",
    ">4. update the parameters of the discriminator $d_\\phi(\\cdot)$ network.\n",
    "\n",
    "The distinct training steps conducted during the regularization phase are the following (generator training):\n",
    "\n",
    ">1. do a journal entry batch forward pass through the generator network to obtain representation $z^{i}_{fake} \\sim q_\\theta(\\cdot)$,\n",
    ">2. compute the generation loss $\\mathcal{L}_{\\theta}^{GEN}(z^{i}_{fake})$, and,\n",
    ">3. update the parameters of the generator $q_\\theta(\\cdot)$ network.\n",
    "\n",
    "To ensure learning while training our AENN model we will monitor whether the distinct losses decrease with progressing training. Therefore, we obtain and evaluate the reconstruction loss $\\mathcal{L}_{\\theta}^{REC}$, the discrimination loss $\\mathcal{L}_{\\theta}^{DIS}$, as well as, the generation loss $\\mathcal{L}_{\\theta}^{GEN}$ of the entire dataset after each training epoch. Based on this evaluation we conclude on the training progress and whether the loss is converging (indicating that the learned model might not improve any further).\n",
    "\n",
    "In addition, after each training epoch we want to save a checkpoint for both the actual `encoder`, `decoder` and `discriminator` model. The saved model checkpoints contain a snapshot of the trained model parameter values upon completion of a training epoch. In general, it is good practice, to save checkpoints at regular intervals during training. In case your system crashes during training you are able continue from the last checkpoint rather than start over from scratch.\n",
    "\n",
    ">- `torch.save()`: saves a checkpoint of the actual encoder and decoder model parameter values to disc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9_TP_8mBqj-"
   },
   "source": [
    "Initialize the per epoch collected model losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SaInCIZCBqj-"
   },
   "outputs": [],
   "source": [
    "# init collection of training losses\n",
    "epoch_reconstruction_losses = []\n",
    "epoch_discriminator_losses = []\n",
    "epoch_generator_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldlDCuyRBqj_"
   },
   "source": [
    "Define the verbose step size of the adversarial autoencoder training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZqwzewXBqj_"
   },
   "outputs": [],
   "source": [
    "mini_batch_verbose_step = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6usKHnkBqkA"
   },
   "source": [
    "Let's now start the adversarial autoencoder network training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "nq5Ba-2bBqkA",
    "outputId": "9dd806be-7b21-4edb-c884-04537c6fd593"
   },
   "outputs": [],
   "source": [
    "# initialize training adversarial autoencoder model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init mini batch counter\n",
    "    mini_batch_count = 0\n",
    "    \n",
    "    # init epoch training losses\n",
    "    batch_reconstruction_losses = 0.0\n",
    "    batch_discriminator_losses = 0.0\n",
    "    batch_generator_losses = 0.0\n",
    "\n",
    "    # determine if GPU training is enabled\n",
    "    if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "        # set all networks / models in GPU mode\n",
    "        encoder_train.cuda()\n",
    "        decoder_train.cuda()\n",
    "        discriminator_train.cuda()\n",
    "\n",
    "    # set networks in training mode (apply dropout when needed)\n",
    "    encoder_train.train()\n",
    "    decoder_train.train()\n",
    "    discriminator_train.train()\n",
    "    \n",
    "    # start timer\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # iterate over epoch mini batches\n",
    "    for mini_batch_data in dataloader:\n",
    "\n",
    "        # increase mini batch counter\n",
    "        mini_batch_count += 1\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "          \n",
    "            # convert mini batch to torch variable\n",
    "            mini_batch_torch = torch.cuda.FloatTensor(mini_batch_data)\n",
    "\n",
    "        else:\n",
    "          \n",
    "             # convert mini batch to torch variable\n",
    "             mini_batch_torch = torch.FloatTensor(mini_batch_data)\n",
    "        \n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "        # =================== reconstruction phase =====================\n",
    "        \n",
    "        # run autoencoder encoding - decoding\n",
    "        z_sample = encoder_train(mini_batch_torch)\n",
    "        mini_batch_reconstruction = decoder_train(z_sample)\n",
    "\n",
    "        # split input date to numerical and categorical part\n",
    "        batch_cat = mini_batch_torch[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "        batch_num = mini_batch_torch[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "        \n",
    "        # split reconstruction to numerical and categorical part\n",
    "        rec_batch_cat = mini_batch_reconstruction[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "        rec_batch_num = mini_batch_reconstruction[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "\n",
    "        # backward pass + gradients update\n",
    "        rec_error_cat = reconstruction_criterion_categorical(input=rec_batch_cat, target=batch_cat)  # one-hot attr error\n",
    "        rec_error_num = reconstruction_criterion_numeric(input=rec_batch_num, target=batch_num)  # numeric attr error\n",
    "\n",
    "        # combine both reconstruction errors\n",
    "        reconstruction_loss = rec_error_cat + rec_error_num\n",
    "        \n",
    "        # run backward pass - determine gradients\n",
    "        reconstruction_loss.backward()\n",
    "        \n",
    "        # collect batch reconstruction loss\n",
    "        batch_reconstruction_losses += reconstruction_loss.item()\n",
    "        \n",
    "        # update network parameter - decoder and encoder\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # =================== regularization phase =====================\n",
    "        # =================== discriminator training ===================\n",
    "\n",
    "        # set discriminator in evaluation mode\n",
    "        discriminator_train.eval()\n",
    "\n",
    "        # generate target latent space data\n",
    "        z_target_batch = z_continous_samples_all[random.sample(range(0, z_continous_samples_all.shape[0]), mini_batch_size),:]\n",
    "\n",
    "        # convert to torch tensor\n",
    "        z_target_batch = torch.FloatTensor(z_target_batch)\n",
    "\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "            z_target_batch = z_target_batch.cuda()\n",
    "\n",
    "        # determine mini batch sample generated by the encoder -> fake gaussian sample\n",
    "        z_fake_gauss = encoder_train(mini_batch_torch)\n",
    "\n",
    "        # determine discriminator classification of both samples\n",
    "        d_real_gauss = discriminator_train(z_target_batch) # real sampled gaussian \n",
    "        d_fake_gauss = discriminator_train(z_fake_gauss) # fake created gaussian\n",
    "\n",
    "        # determine discriminator classification target variables\n",
    "        d_real_gauss_target = torch.FloatTensor(torch.ones(d_real_gauss.shape)) # real -> 1\n",
    "        d_fake_gauss_target = torch.FloatTensor(torch.zeros(d_fake_gauss.shape)) # fake -> 0\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "            # push tensors to CUDA\n",
    "            d_real_gauss_target = d_real_gauss_target.cuda()\n",
    "            d_fake_gauss_target = d_fake_gauss_target.cuda()\n",
    "\n",
    "        # determine individual discrimination losses\n",
    "        discriminator_loss_real = discriminator_criterion(target=d_real_gauss_target, input=d_real_gauss) # real loss\n",
    "        discriminator_loss_fake = discriminator_criterion(target=d_fake_gauss_target, input=d_fake_gauss) # fake loss\n",
    "        \n",
    "        # add real loss and fake loss\n",
    "        discriminator_loss = discriminator_loss_fake + discriminator_loss_real\n",
    "\n",
    "        # run backward through the discriminator network\n",
    "        discriminator_loss.backward()\n",
    "        \n",
    "        # collect discriminator loss\n",
    "        batch_discriminator_losses += discriminator_loss.item()\n",
    "\n",
    "        # update network the discriminator network parameters\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "        # =================== regularization phase =====================\n",
    "        # =================== generator training =======================\n",
    "\n",
    "        # set encoder / generator in training mode\n",
    "        encoder_train.train()\n",
    "        \n",
    "        # reset the encoder / generator networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "\n",
    "        # determine fake gaussian sample generated by the encoder / generator\n",
    "        z_fake_gauss = encoder_train(mini_batch_torch)\n",
    "\n",
    "        # determine discriminator classification of fake gaussian sample\n",
    "        d_fake_gauss = discriminator_train(z_fake_gauss)\n",
    "\n",
    "        # determine discriminator classification target variables\n",
    "        d_fake_gauss_target = torch.FloatTensor(torch.ones(d_fake_gauss.shape)) # fake -> 1\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "            # push tensors to CUDA\n",
    "            d_fake_gauss_target = d_fake_gauss_target.cuda()\n",
    "\n",
    "        # determine discrimination loss of fake gaussian sample\n",
    "        generator_loss = discriminator_criterion(target=d_fake_gauss_target, input=d_fake_gauss)\n",
    "        \n",
    "        # collect generator loss\n",
    "        batch_generator_losses += generator_loss.item()\n",
    "\n",
    "        # run backward pass - determine gradients\n",
    "        generator_loss.backward()\n",
    "\n",
    "        # update network paramaters - encoder / generatorc\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "    # collect epoch training losses - reconstruction loss\n",
    "    epoch_reconstruction_loss = batch_reconstruction_losses / mini_batch_count\n",
    "    epoch_reconstruction_losses.extend([epoch_reconstruction_loss])\n",
    "    \n",
    "    # collect epoch training losses - discriminator loss\n",
    "    epoch_discriminator_loss = batch_discriminator_losses / mini_batch_count\n",
    "    epoch_discriminator_losses.extend([epoch_discriminator_loss])\n",
    "    \n",
    "    # collect epoch training losses - generator loss\n",
    "    epoch_generator_loss = batch_generator_losses / mini_batch_count\n",
    "    epoch_generator_losses.extend([epoch_generator_loss])\n",
    "    \n",
    "    # print epoch reconstruction loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, reconstruction loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_reconstruction_loss))\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, discriminator loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_discriminator_loss))\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, generator loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_generator_loss))\n",
    "    \n",
    "    # =================== save model snapshots to disk ============================\n",
    "    \n",
    "    # save trained encoder model file to disk\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H_%M_%S\")\n",
    "    encoder_model_name = \"{}_ep_{}_encoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(encoder_train.state_dict(), os.path.join(\"./models\", encoder_model_name))\n",
    "\n",
    "    # save trained decoder model file to disk\n",
    "    decoder_model_name = \"{}_ep_{}_decoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(decoder_train.state_dict(), os.path.join(\"./models\", decoder_model_name))\n",
    "    \n",
    "    # save trained discriminator model file to disk\n",
    "    decoder_model_name = \"{}_ep_{}_discriminator_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(discriminator_train.state_dict(), os.path.join(\"./models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tnHdNC0nBqkA"
   },
   "source": [
    "Let's now evaluate the magnitude of the distinct losses with progressing training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "wkrpELqHBqkA",
    "outputId": "3b8a71cf-5278-4c0f-95a4-da55b3557bb9"
   },
   "outputs": [],
   "source": [
    "# plot the reconstruction loss per training epoch\n",
    "plt.plot(range(1, len(epoch_reconstruction_losses)+1), epoch_reconstruction_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AAE training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('reconstruction loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "e4g9UCw1BqkB",
    "outputId": "6d595937-549b-47a5-d132-68f43d4e148d"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator loss per training epoch\n",
    "plt.plot(range(0, len(epoch_discriminator_losses)), epoch_discriminator_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AENN training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('discrimination loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "xpbcRem9BqkB",
    "outputId": "7510517d-b132-4048-dd8a-1c6c92d8194b"
   },
   "outputs": [],
   "source": [
    "# plot the generator loss per training epoch\n",
    "plt.plot(range(0, len(epoch_generator_losses)), epoch_generator_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AENN training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('generation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kv6lhcx8BqkC"
   },
   "source": [
    "How does the reconstruction loss change as we progress in training our model? After 5 epochs, we can observe that our reconstruction loss already went down significantly and starts to converge nicely. This indicates that our network did a pretty good job in learning the structure and attributes of the journal entries.\n",
    "\n",
    "But, from the plot we also observe that the model could probably be trained a couple more epochs as the trend of the reconstruction error still decreases for the last few epochs. In order to save time, we will continue the lab using a pre-trained model already trained by 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoQOZj-rBqkC"
   },
   "source": [
    "## 5. Evaluating the Autoencoder Neural Network (AENN) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ha6OVXjTBqkC"
   },
   "source": [
    "In order, to detect interpretable accounting anomalies in real-world ERP datasets we propose a novel anomaly score utilizing the introduced AAE architecture. The score builds on the regularisation applied throughout the AAE training process, namely the reconstruction error loss and the adversarial loss, described in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54rLvmZXBqkC"
   },
   "source": [
    "As the training of such model is computationally expensive, within the scope of this notebook we provide the pretrained model (400 training epochs) that can be used to assess the proposed anomaly score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pv35N4kEBqkC",
    "outputId": "c6f0c4ac-5a22-432c-e4b5-820988b0cb90"
   },
   "outputs": [],
   "source": [
    "\n",
    "# restore pretrained model checkpoint\n",
    "encoder_model_name = 'https://raw.githubusercontent.com/GitiHubi/deepAD/master/models/20190818-03_22_18_ep_401_encoder_model.pth'\n",
    "decoder_model_name = 'https://raw.githubusercontent.com/GitiHubi/deepAD/master/models/20190818-03_22_18_ep_401_decoder_model.pth'\n",
    "\n",
    "# Read stored model from the remote location\n",
    "encoder_bytes = urllib.request.urlopen(encoder_model_name)\n",
    "decoder_bytes = urllib.request.urlopen(decoder_model_name)\n",
    "\n",
    "# Load tensor from io.BytesIO object\n",
    "encoder_buffer = io.BytesIO(encoder_bytes.read())\n",
    "decoder_buffer = io.BytesIO(decoder_bytes.read())\n",
    "\n",
    "# init training network classes / architectures\n",
    "encoder_eval = Encoder(input_size=ori_subset_transformed.shape[1], hidden_size=[256, 64, 16, 4, 2])\n",
    "decoder_eval = Decoder(output_size=ori_subset_transformed.shape[1], hidden_size=[2, 4, 16, 64, 256])\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    encoder_eval = encoder_eval.cuda()\n",
    "    decoder_eval = decoder_eval.cuda()\n",
    "    \n",
    "# load trained models\n",
    "encoder_eval.load_state_dict(torch.load(encoder_buffer))\n",
    "decoder_eval.load_state_dict(torch.load(decoder_buffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpXoyzWrBqkD"
   },
   "source": [
    "Let's also specify a dataloader that provides the ability to evaluate the journal entrie in an \"unshuffled\" batch-wise manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IJRjyXqBqkD"
   },
   "outputs": [],
   "source": [
    "# convert pre-processed data to pytorch tensor\n",
    "torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()\n",
    "\n",
    "# convert to pytorch tensor - none cuda enabled\n",
    "dataloader_eval = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# determine if CUDA is available at the compute node\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    \n",
    "    # push dataloader to CUDA\n",
    "    dataloader_eval = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BycUlpLBqkD"
   },
   "source": [
    "### 5.1 Visualize the Latent Space Represenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW9cvdFwBqkE"
   },
   "source": [
    "Perform the feed forward pass through the pretrained encoder model and collect learned representations of all journal entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0M9EGtWBqkE"
   },
   "outputs": [],
   "source": [
    "# set networks in evaluation mode (don't apply dropout)\n",
    "encoder_eval.eval()\n",
    "decoder_eval.eval()\n",
    "\n",
    "# init batch count\n",
    "batch_count = 0\n",
    "\n",
    "# iterate over epoch mini batches\n",
    "for enc_transactions_batch in dataloader_eval:\n",
    "\n",
    "    # determine latent space representation of all transactions\n",
    "    z_enc_transactions_batch = encoder_eval(enc_transactions_batch)\n",
    "    \n",
    "    # case: initial batch \n",
    "    if batch_count == 0:\n",
    "\n",
    "      # collect reconstruction errors of batch\n",
    "      z_enc_transactions_all = z_enc_transactions_batch\n",
    "      \n",
    "    # case: non-initial batch\n",
    "    else:\n",
    "      \n",
    "      # collect reconstruction errors of batch\n",
    "      z_enc_transactions_all = torch.cat((z_enc_transactions_all, z_enc_transactions_batch), dim=0)\n",
    "    \n",
    "    # increase batch count\n",
    "    batch_count += 1\n",
    "\n",
    "# convert to numpy array\n",
    "z_enc_transactions_all = z_enc_transactions_all.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMGA1GTlBqkE"
   },
   "source": [
    "Let's visually inspect the learned latent space representation obtained of each journal entry $x^{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "colab_type": "code",
    "id": "K9P4oQaXBqkE",
    "outputId": "4b0193f0-ae75-4012-feb9-0ba15d9dad01"
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# obtain regular transactions as well as global and local anomalies\n",
    "regular_data = z_enc_transactions_all[label == 'regular']\n",
    "global_outliers = z_enc_transactions_all[label == 'global']\n",
    "local_outliers = z_enc_transactions_all[label == 'local']\n",
    "\n",
    "# plot reconstruction error scatter plot\n",
    "ax.scatter(regular_data[:, 0], regular_data[:, 1], c='C0', marker=\"o\", label='regular', edgecolors='w', linewidth=0.5) # plot regular transactions\n",
    "ax.scatter(global_outliers[:, 0], global_outliers[:, 1], c='C1', marker=\"x\", label='global', edgecolors='w', s=60) # plot global outliers\n",
    "ax.scatter(local_outliers[:, 0], local_outliers[:, 1], c='C3', marker=\"x\", label='local', edgecolors='w', s=60) # plot local outliers\n",
    "\n",
    "# add plot legend of transaction classes\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZ_v__AvBqkF"
   },
   "source": [
    "### 5.2 Determine Normalized Mode Divergence (MD) of Each Journal Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wsz6oQ-BqkF"
   },
   "source": [
    "Journal entries that exhibit anomalous attribute values (global anomalies) result in an increased divergence from the imposed multi-modal prior, e.g., as in this work the divergence to the modes of an imposed mixture of multivariate isotropic Gaussians $\\mathcal{N}(\\mu,\\mathcal{I})$, where $\\mu \\in \\mathcal{R}^m$ defines the $\\tau$ modes of the distinct Gaussians denoted by $\\mu =\\{\\mu^1 \\ldots \\mu^\\tau \\}$. Throughout the AAE training, the entries will be \"pushed\" towards the high probability density regions of the prior by the regularization. In order to be able to discriminate between the imposed prior and the learned aggregated posterior the AAE aims to keep the majority of the entries within the high-density regions (modes) of the prior. In contrast, representations that correspond to rare or anomalous journal entries will tend to differ from the imposed modes and be placed in the priors low-density regions. We use this characteristic and obtain an entry's $x^{i}$ mode divergence $D$ as the Euclidean distance of the entry's learned representation $z^i$ to its closest mode $\\mu^\\tau$. Formally, we derive the mode divergence as denoted by $D_{\\theta^*}^{\\tau}(z^{i};\\mu) = \\min\\limits_{\\tau} \\lVert z^i-\\mu^\\tau \\rVert^2 $ under optimal model parameters $\\theta^*$. Finally, we calculate the normalized mode divergence $MD$ as expressed by:\n",
    "\n",
    "\\begin{equation}\n",
    "MD_{\\theta^*}^{\\tau}(x^{i}) = \\frac{D_{\\theta^*}^{\\tau}(z^i;\\mu) - D_{\\theta^*, min}^{\\tau}}{D_{\\theta^*, max}^{\\tau} - D_{\\theta^*, min}^{\\tau}},\n",
    "\\end{equation}\n",
    "\n",
    "where $D_{min}$ and $D_{max}$ denotes the min- and max-values of the obtained mode divergences given by $D_{\\theta^*}$ and closest mode $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35iFX_etBqkF"
   },
   "outputs": [],
   "source": [
    "# define euclidean distance calculation\n",
    "def compute_euclid_distance(x, y):\n",
    "    \n",
    "    # calculate euclidean distance \n",
    "    euclidean_distance = np.sqrt(np.sum((x - y) ** 2, axis=1))\n",
    "    \n",
    "    # return euclidean distance\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGx1sDrABqkF"
   },
   "source": [
    "Obtain the mode assignment and mode divergence of each journal entry $x^{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dd_LQqFsBqkG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# determine distance to each mode\n",
    "distances = np.apply_along_axis(func1d=compute_euclid_distance, axis=1, arr=z_enc_transactions_all, y=mu_gauss)\n",
    "\n",
    "# determine mode divergence\n",
    "mode_divergence = np.min(distances, axis=1)\n",
    "\n",
    "# determine min-mode id\n",
    "cluster_ids = np.argmin(distances, axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxEPbeTfBqkG"
   },
   "source": [
    "Normalize the obtained mode divergenes $D_{\\theta^*}^{\\tau}$ of each mode $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNOsg4lsBqkG"
   },
   "outputs": [],
   "source": [
    "# normalize the mode divergences of each mode\n",
    "\n",
    "# prepare empty arrays of the same shape and dtype\n",
    "mode_divergence_all_scaled = np.asarray(mode_divergence)\n",
    "\n",
    "# iterate over the cluster modes\n",
    "for cluster_id in np.unique(cluster_ids).tolist():\n",
    "  \n",
    "    # determine journal entries of current mode\n",
    "    mask = cluster_ids == cluster_id\n",
    "\n",
    "    # normalize mode journal entries mode divergence to the range [0,1]\n",
    "    mode_divergence_all_scaled[mask] = (mode_divergence[mask] - mode_divergence[mask].min()) / (mode_divergence[mask].ptp())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEisc853BqkH"
   },
   "source": [
    "Let's visually inspect the obtained mode divergence obtained of each journal entry $x^{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "xNxfJuQTBqkH",
    "outputId": "92d04476-405b-412a-80e3-248e230a9148"
   },
   "outputs": [],
   "source": [
    "\n",
    "# collect anomaly score, labels and cluster assignments\n",
    "plot_data = pd.concat([pd.Series(mode_divergence_all_scaled, name='mode_divergence'), \n",
    "                       pd.Series(label, name='label'),                        \n",
    "                       pd.Series(cluster_ids, name='cluster_id')],\n",
    "                     axis=1)\n",
    "\n",
    "num_clusters = len(np.unique(cluster_ids))\n",
    "# init sub-plots based on the number of modes\n",
    "fig, axes = plt.subplots(1, num_clusters, sharey=True, figsize=(14, 10))\n",
    "\n",
    "\n",
    "# iterate over distinct modes\n",
    "for mode in range(0, num_clusters):\n",
    "\n",
    "    plot_data = plot_data.sample(frac=1.0)\n",
    "    # collect features of current mode\n",
    "    z_mode = plot_data[plot_data['cluster_id'] == mode]\n",
    "\n",
    "    regular_data = z_mode[z_mode['label'] == 'regular']\n",
    "    global_outliers = z_mode[z_mode['label'] == 'global']\n",
    "    local_outliers = z_mode[z_mode['label'] == 'local']\n",
    "\n",
    "    # create train scatter plot of regular samples\n",
    "    axes[mode].scatter(regular_data.index, regular_data['mode_divergence'],\n",
    "                       c='C0', marker='o', s=30, linewidth=0.3, label='regular', edgecolors='w')\n",
    "    \n",
    "    # create train scatter plot of global anomalies\n",
    "    axes[mode].scatter(global_outliers.index, global_outliers['mode_divergence'],\n",
    "                               c='C1', marker='x', s=120, linewidth=3, label='global', edgecolors='w')\n",
    "    # create train scatter plot of local anomalies\n",
    "    axes[mode].scatter(local_outliers.index, local_outliers['mode_divergence'],\n",
    "                               c='C3', marker='x', s=120, linewidth=3, label='local', edgecolors='w')\n",
    "\n",
    "    # set axis labels\n",
    "    xlabel = '$\\\\tau={}$' + str(mode+1) if mode == 0 else str(mode+1)\n",
    "    axes[mode].set_xlabel(xlabel, fontsize=24)\n",
    "\n",
    "    # set axis limits\n",
    "    axes[mode].set_ylim([0.0, 1.1])\n",
    "\n",
    "    axes[mode].set_xticks([int(plot_data.shape[0]/2)])\n",
    "    axes[mode].set_xticklabels(['$x_{i}$'])\n",
    "\n",
    "# set axis labels\n",
    "axes[0].set_ylabel('mode divergence $MD$', fontsize=20)\n",
    "\n",
    "# add legend to plot\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, loc='center', fontsize=20, ncol=3, borderaxespad=0.,\n",
    "           bbox_to_anchor=(-6.5, 1., 9., .1))\n",
    "\n",
    "# set grid and tight plotting layout\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h27jv8E9BqkH"
   },
   "source": [
    "### 5.3 Determine Normalized Reconstruction Error (RE) of Each Journal Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n89gRgosBqkH"
   },
   "source": [
    "Journal entries that exhibit anomalous attribute value co-occurrences (local anomalies) tend to result in an increased reconstruction error. This is caused by the compression capability of the AAE architecture. Anomalous and therefore unique attribute co-occurrences exhibit an increased probability of getting lost in the encoders \"lossy\" compression. As a result, their low dimensional representation will overlap with regular entries in the latent space and are not reconstructed correctly by the decoder. Formally, we obtain the reconstruction error $E$ of each entry $x^i$ and its reconstruction $\\hat{x}^i$ as the squared-difference denoted by $E_{\\theta^*}^{\\tau}(x^{i};\\hat{x}^{i}) = \\frac{1}{k} \\sum_{j=1}^{k}{(x^{i}_{j} - \\hat{x}^{i}_{j})}^2$ under optimal model parameters $\\theta^*$. Finally, we calculate the normalized reconstruction error $RE$ as expressed by:\n",
    "\n",
    "\\begin{equation}\n",
    "RE_{\\theta^*}^{\\tau}(x^{i};\\hat{x}^{i}) = \\frac{E_{\\theta^*}^{\\tau}(x^i;\\hat{x}^{i}) - E_{\\theta^*, min}^{\\tau}}{E_{\\theta^*, max}^{\\tau} - E_{\\theta^*, min}^{\\tau}},\n",
    "\\end{equation}\n",
    "\n",
    "where $E_{min}$ and $E_{max}$ denotes the min- and max-values of the obtained reconstruction errors given by $E_{\\theta^*}$ and closest mode $\\tau$. Let's obtain the reconstruction error of each journal entry $x^{i}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsEtBljsBqkH"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "reconstruction_criterion_categorical_eval = nn.BCEWithLogitsLoss(reduction='none')\n",
    "reconstruction_criterion_numeric_eval = nn.MSELoss(reduction='none')\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    reconstruction_criterion_categorical_eval = reconstruction_criterion_categorical_eval.cuda()\n",
    "    reconstruction_criterion_numeric_eval = reconstruction_criterion_numeric_eval.cuda()\n",
    "\n",
    "# set networks in evaluation mode (don't apply dropout)\n",
    "encoder_eval.eval()\n",
    "decoder_eval.eval()\n",
    "\n",
    "# init batch count\n",
    "batch_count = 0\n",
    "\n",
    "# iterate over epoch mini batches\n",
    "for enc_transactions_batch in dataloader_eval:\n",
    "\n",
    "    # determine latent space representation of all transactions\n",
    "    z_enc_transactions_batch = encoder_eval(enc_transactions_batch)\n",
    "\n",
    "    # reconstruct input samples\n",
    "    reconstruction_batch = decoder_eval(z_enc_transactions_batch)\n",
    "\n",
    "    # split input transactions into numeric and categorical parts\n",
    "    input_cat_all = enc_transactions_batch[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "    input_num_all = enc_transactions_batch[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "\n",
    "    # split reconstruction into numeric and categorical parts\n",
    "    rec_cat_all = reconstruction_batch[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "    rec_num_all = reconstruction_batch[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "\n",
    "    # compute rec error\n",
    "    rec_error_cat_all = reconstruction_criterion_categorical_eval(input=rec_cat_all, target=input_cat_all).mean(dim=1)\n",
    "    rec_error_num_all = reconstruction_criterion_numeric_eval(input=rec_num_all, target=input_num_all).mean(dim=1)\n",
    "\n",
    "    # combine categorical and numerical errors\n",
    "    rec_error_all_batch = rec_error_cat_all + rec_error_num_all\n",
    "    \n",
    "    # case: initial batch\n",
    "    if batch_count == 0:\n",
    "    \n",
    "      # collect reconstruction errors of batch\n",
    "      rec_error_all = rec_error_all_batch\n",
    "    \n",
    "    # case: non-initial batch\n",
    "    else:\n",
    "      \n",
    "      # collect reconstruction errors of batch\n",
    "      rec_error_all = torch.cat((rec_error_all, rec_error_all_batch), dim=0)\n",
    "    \n",
    "    # increase batch count\n",
    "    batch_count += 1\n",
    "\n",
    "# convert to numpy array\n",
    "rec_error_all = rec_error_all.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgGyJtnSBqkI"
   },
   "source": [
    "Normalize the obtained reconstruction errors $E_{\\theta^*}^{\\tau}$ of each mode $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6OXNSRTBqkI"
   },
   "outputs": [],
   "source": [
    "# normalize the reconstruction errors of each mode\n",
    "\n",
    "# prepare empty arrays of the same shape and dtype\n",
    "rec_error_all_scaled = np.asarray(rec_error_all)\n",
    "\n",
    "# iterate over the cluster modes\n",
    "for cluster_id in np.unique(cluster_ids).tolist():\n",
    "  \n",
    "    # determine journal entries of current mode\n",
    "    mask = cluster_ids == cluster_id\n",
    "\n",
    "    # normalize mode journal entries reconstruction error to the range [0,1]\n",
    "    rec_error_all_scaled[mask] = (rec_error_all[mask] - rec_error_all[mask].min()) / (rec_error_all[mask].ptp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2oxpMUtjBqkI"
   },
   "source": [
    "Let's visually inspect the reconstruction error obtained for each journal entry $x^{i}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "v25TKzLEBqkI",
    "outputId": "2010716d-2fb6-433e-aafa-d8a438e8a10e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# collect anomaly score, labels and cluster assignments\n",
    "plot_data = pd.concat([pd.Series(rec_error_all_scaled, name='rec_error'), \n",
    "                       pd.Series(label, name='label'),                        \n",
    "                       pd.Series(cluster_ids, name='cluster_id')],\n",
    "                     axis=1)\n",
    "\n",
    "num_clusters = len(np.unique(cluster_ids))\n",
    "# init sub-plots based on the number of modes\n",
    "fig, axes = plt.subplots(1, num_clusters, sharey=True, figsize=(14, 10))\n",
    "\n",
    "\n",
    "# iterate over distinct modes\n",
    "for mode in range(0, num_clusters):\n",
    "\n",
    "    plot_data = plot_data.sample(frac=1.0)\n",
    "    # collect features of current mode\n",
    "    z_mode = plot_data[plot_data['cluster_id'] == mode]\n",
    "\n",
    "    regular_data = z_mode[z_mode['label'] == 'regular']\n",
    "    global_outliers = z_mode[z_mode['label'] == 'global']\n",
    "    local_outliers = z_mode[z_mode['label'] == 'local']\n",
    "\n",
    "    # create train scatter plot of regular samples\n",
    "    axes[mode].scatter(regular_data.index, regular_data['rec_error'],\n",
    "                       c='C0', marker='o', s=30, linewidth=0.3, label='regular', edgecolors='w')\n",
    "    \n",
    "    # create train scatter plot of global anomalies\n",
    "    axes[mode].scatter(global_outliers.index, global_outliers['rec_error'],\n",
    "                               c='C1', marker='x', s=120, linewidth=3, label='global', edgecolors='w')\n",
    "    # create train scatter plot of local anomalies\n",
    "    axes[mode].scatter(local_outliers.index, local_outliers['rec_error'],\n",
    "                               c='C3', marker='x', s=120, linewidth=3, label='local', edgecolors='w')\n",
    "\n",
    "    # set axis labels\n",
    "    xlabel = '$\\\\tau={}$' + str(mode+1) if mode == 0 else str(mode+1)\n",
    "    axes[mode].set_xlabel(xlabel, fontsize=24)\n",
    "\n",
    "    # set axis limits\n",
    "    axes[mode].set_ylim([0.0, 1.1])\n",
    "\n",
    "    axes[mode].set_xticks([int(plot_data.shape[0]/2)])\n",
    "    axes[mode].set_xticklabels(['$x_{i}$'])\n",
    "\n",
    "# set axis labels\n",
    "axes[0].set_ylabel('reconstruction error $RE$', fontsize=20)\n",
    "\n",
    "# add legend to plot\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, loc='center', fontsize=20, ncol=3, borderaxespad=0.,\n",
    "           bbox_to_anchor=(-6.5, 1., 9., .1))\n",
    "\n",
    "# set grid and tight plotting layout\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKOEWs9uBqkJ"
   },
   "source": [
    "### 5.3 Determine Anomaly Score $AS^{\\tau}$ of Each Journal Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-XzRvnHWBqkJ"
   },
   "source": [
    "Quantifying both characteristics for a given journal entry, we can reasonably conclude (1) if the entry is anomalous and (2) if it was created by a \"regular\" business activity. To detect global and local accounting anomalies in real-world audit scenarios we propose to score each journal entry $x^i$ by its normalized reconstruction error $RE$ regularized and normalized mode divergence $MD$ given by:\n",
    "\n",
    "\\begin{equation}\n",
    "AS^{\\tau}(x^{i};\\hat{x}^{i}) = \\alpha \\times RE_{\\theta^*}^{\\tau}(x^{i};\\hat{x}^{i}) + (1-\\alpha) \\times MD_{\\theta^*}^{\\tau}(x^{i}),\n",
    "\\end{equation} \n",
    "\n",
    "for each individual journal entry $x^{i}$ and optimal model parameters $\\theta^*$ and closest mode $\\tau$. We introduce $\\alpha$ as a factor to balance both characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-0DJy2SBqkJ"
   },
   "outputs": [],
   "source": [
    "# set alpha \n",
    "alpha = 0.4\n",
    "\n",
    "# determine journal entry anomaly score\n",
    "anomaly_score = alpha * rec_error_all_scaled + (1.0 - alpha) * mode_divergence_all_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlyJpQT9BqkL"
   },
   "source": [
    "### 5.4 Visual Inspection of the Obtained Anomaly Scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPhizQIFBqkL"
   },
   "source": [
    "Let's visually inspect the obtained anomaly scores obtained for each journal entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "QwFmh4f1BqkL",
    "outputId": "f9085ecb-de33-41cd-9c67-adf16bd0da58"
   },
   "outputs": [],
   "source": [
    "\n",
    "# collect anomaly score, labels and cluster assignments\n",
    "plot_data = pd.concat([pd.Series(anomaly_score, name='anomaly_score'), \n",
    "                       pd.Series(label, name='label'),                        \n",
    "                       pd.Series(cluster_ids, name='cluster_id')],\n",
    "                     axis=1)\n",
    "\n",
    "num_clusters = len(np.unique(cluster_ids))\n",
    "# init sub-plots based on the number of modes\n",
    "fig, axes = plt.subplots(1, num_clusters, sharey=True, figsize=(14, 10))\n",
    "\n",
    "# iterate over distinct modes\n",
    "for mode in range(0, num_clusters):\n",
    "\n",
    "    plot_data = plot_data.sample(frac=1.0)\n",
    "    # collect features of current mode\n",
    "    z_mode = plot_data[plot_data['cluster_id'] == mode]\n",
    "\n",
    "    regular_data = z_mode[z_mode['label'] == 'regular']\n",
    "    global_outliers = z_mode[z_mode['label'] == 'global']\n",
    "    local_outliers = z_mode[z_mode['label'] == 'local']\n",
    "\n",
    "    # create train scatter plot of regular samples\n",
    "    axes[mode].scatter(regular_data.index, regular_data['anomaly_score'],\n",
    "                       c='C0', marker='o', s=30, linewidth=0.3, label='regular', edgecolors='w')\n",
    "    \n",
    "    # create train scatter plot of global anomalies\n",
    "    axes[mode].scatter(global_outliers.index, global_outliers['anomaly_score'],\n",
    "                               c='C1', marker='x', s=120, linewidth=3, label='global', edgecolors='w')\n",
    "    # create train scatter plot of local anomalies\n",
    "    axes[mode].scatter(local_outliers.index, local_outliers['anomaly_score'],\n",
    "                               c='C3', marker='x', s=120, linewidth=3, label='local', edgecolors='w')\n",
    "\n",
    "    # set axis labels\n",
    "    xlabel = '$\\\\tau={}$' + str(mode+1) if mode == 0 else str(mode+1)\n",
    "    axes[mode].set_xlabel(xlabel, fontsize=24)\n",
    "\n",
    "    # set axis limits\n",
    "    axes[mode].set_ylim([0.0, 1.1])\n",
    "\n",
    "    axes[mode].set_xticks([int(plot_data.shape[0]/2)])\n",
    "    axes[mode].set_xticklabels(['$x_{i}$'])\n",
    "\n",
    "# set axis labels\n",
    "axes[0].set_ylabel('anomaly score $AS$', fontsize=20)\n",
    "\n",
    "# add legend to plot\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "plt.legend(handles, labels, loc='center', fontsize=20, ncol=3, borderaxespad=0.,\n",
    "           bbox_to_anchor=(-6.5, 1., 9., .1))\n",
    "\n",
    "# set grid and tight plotting layout\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYqRpiYnBqkL"
   },
   "source": [
    "The visualization reveals that the pre-trained model is able to reconstruct the majority of regular journal entries, while failing to do so, for the anomalous ones. As a result, the model reconstruction error can be used to distinguish both \"global\" anomalies (orange) and \"local\" anomalies (green) from the regular journal entries (blue).\n",
    "\n",
    "To further investigate our observation and confirm the initial assumption, let's have a closer look into the journal entries exhibiting an anomaly score >= 0.25 selected from the cluster mode $\\tau=3$. We assume that these journal entries correspond to the \"global\" anomalies of the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2TpJytaRBqkL",
    "outputId": "16fe9b35-dae6-4e08-9533-ce1e6fbf8cb1"
   },
   "outputs": [],
   "source": [
    "ori_dataset['label'] = label\n",
    "ori_dataset['tau'] = cluster_ids\n",
    "\n",
    "# inspect transactions exhibiting a reconstruction error >= 0.2\n",
    "ori_dataset[(anomaly_score >= 0.25) & (cluster_ids == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj7GovE_BqkM"
   },
   "source": [
    "Let's now also have a closer look into the journal entries exhibiting anomaly score >= 0.4 selected from the cluster mode $\\tau=2$. We assume that these journal entries mostly correspond to the \"local\" anomalies of the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "dmKQmznCBqkM",
    "outputId": "baa2f46a-65b7-44eb-f044-0aa5debd0663"
   },
   "outputs": [],
   "source": [
    "# inspect transactions exhibiting a anomaly_score >= 0.4 from the mode 2\n",
    "ori_dataset[(anomaly_score >= 0.4) & (cluster_ids == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h9s5Awk7BqkM",
    "outputId": "5173ae1e-19c1-4669-b388-58f2fc66293d"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script KDD_2019.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hM4jR_zqBqkN"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDT_fIjMBqkN"
   },
   "source": [
    "Major elements of the lab content are inspired by the publication \"Detection of Anomalies in Large Scale Accounting Data using Deep Autoencoder Networks\", of M. Schreyer, T. Sattarov, D. S. Borth, A. Dengel, and B. Reimer, 2017 (arXiv preprint available under: https://arxiv.org/abs/1709.05254).\n",
    "\n",
    "[1] ACFE, \"Report to the Nations on Occupational Fraud and Abuse\", The 2016 Global Fraud Study, Association of Certified Fraud Examiners (ACFE), 2016.\n",
    "\n",
    "[2] J. T. Wells, \"Corporate Fraud Handbook: Prevention and Detection\", John Wiley & Sons, 2017.\n",
    "\n",
    "[3] PwC, \"Pulling Fraud Out of the Shadows\", The Global Economic Crime and Fraud Survey 2018, PricewaterhouseCoopers LLP, 2018.\n",
    "\n",
    "[4] S. Markovitch, P. Willmott, \"Accelerating the digitization of business processes\", McKinsey & Company (2014) 1–5.\n",
    "\n",
    "[5] SAP, SAP Global Corporate Affairs, Corporate Factsheet 2017, 2017.\n",
    "\n",
    "[6] E. A. Lopez-Rojas , A. Elmir, and S. Axelsson, \"PaySim: A financial mobile money simulator for fraud detection\", In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus, 2016.\n",
    "\n",
    "[7] G. E. Hinton, and R. R. Salakhutdinov, \"Reducing the dimensionality of data with neural networks\", science 313, no. 5786: 504-507, 2006.\n",
    "\n",
    "[8] N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, \"Dropout: A simple way to prevent neural networks from overfitting\", The Journal of Machine Learning Research, 15(1), 1929-1958, 2014.\n",
    "\n",
    "[9] X. Glorot and Y. Bengio, \"Understanding the difficulty of training deep feedforward neural networks\", Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), 9:249–256, 2010.\n",
    "\n",
    "[10] B. Xu, N. Wang, T. Chen, and M. Li, \"Empirical Evaluation of Rectified Activations in Convolution Network\", ICML Deep Learning Workshop, pages 1–5, 2015.\n",
    "\n",
    "[11] D. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization\", International Conference on Learning Representations (ICLR). 2015.\n",
    "\n",
    "[12] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, R. R. Salakhutdinov. \"Improving neural networks by preventing co-adaptation of feature detectors\", Technical Report, 2012.\n",
    "\n",
    "[13] D. P. Kingma, M. Welling. \"Auto-encoding variational bayes\", arXiv preprint arXiv:1312.6114, 2013.\n",
    "\n",
    "[14] Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., & Frey, B., \"Adversarial autoencoders\", arXiv preprint arXiv:1511.05644, 2015.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "colab_06.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
