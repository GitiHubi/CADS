{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dojtwAh1Ww1B"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"./fs_logo.png\">\n",
    "\n",
    "##  Lab 04 - Supervised Deep Learning\n",
    "\n",
    "Seminar Künstliche Intelligenz, Frankfurt School, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analysen des Seminars **Künstliche Intelligenz** des Zertifikatstudiengangs **Certified Audit Data Scientist (CADS)** basieren auf Jupyter Notebook. Anhand solcher Notebooks ist es möglich eine Vielzahl von Datenanalysen und statistischen Validierungen durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yaWalgW_d7j"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./lab_04_banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR4Ywe2HWw1M"
   },
   "source": [
    "Im letzten Lab haben Sie die verschiedenen Elemente eines Unsupervised Machine Learning Workflow kennengelernt z.B. Datenaufbereitung, Modell Training und Modell Validierung. In diesem vierten Lab werden wir Jupyter Notebook verwenden, um einen **Deep Learning basierten Workflow** zu implementieren und anzuwenden.\n",
    "\n",
    "Hierzu werden wir unser erstes **Künstliches Neuronales Netz (ANN)** mit der Python Bibliothek `PyTorch` implementieren, trainieren und evaluieren. Die `PyTorch` Bibliothek ist eine Open-Source Bibliothek für das Deep Learning in Python, die für eine Vielzahl von Anwendungen wie Bildklassifizierung und Verarbeitung natürlicher Sprache verwendet wird. Wir werden das zu implementierende neuronale Netz verwenden, um zu lernen, Bilder des **Zalando Fashion MNIST** Datensatzes zu klassifizieren.\n",
    "\n",
    "Die nachstehende Abbildung zeigt einen Überblick über den Deep Learning Prozess bzw. die ANN Netzarchitektur, welche wir in diesem Lab implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgQ_ksmaWw1N"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 800px\" src=\"./classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-9LY1AjWw1O"
   },
   "source": [
    "Bei etwaigen Fragen wenden Sie sich, wie immer gerne an uns via **marco (dot) schreyer (at) efk (dot) admin (dot) ch**. Wir wünschen Ihnen Viel Freude mit unseren Notebooks und Ihren revisorischen Analysen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aut1dJXmWw1O"
   },
   "source": [
    "## Lernziele des Labs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tb0svb4Ww1O"
   },
   "source": [
    "Nach der heutigen Übung sollten Sie in der Lage sein:\n",
    "\n",
    "> 1. Die **Grundkonzepte, Funktionsweise und Bestandteile** von Künstlichen Neuronalen Netzen zu verstehen.\n",
    "> 2. Künstliche Neuronale Netze zur **Klassifikation** unterschiedlichster Datensätze anzuwenden.\n",
    "> 3. Die Funktionalität der PyTorch Bibliothek für die **Implementierung** und das **Training** von KNN Modellen zu nutzen.\n",
    "> 4.  Die **Ergebnisse** der Deep Learning basierten Klassifiktion zu interpretieren und einzuschätzen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks081EJEWw1P"
   },
   "source": [
    "## 1. Einrichten der Analyseumgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdmhjYHFWw1P"
   },
   "source": [
    "Ähnlich wie in den vorangegangenen Übungen werden wir zunächst eine Reihe von Python-Bibliotheken importieren, welche die Datenanalyse und -visualisierung ermöglichen. In dieser Übung werden wir die Bibliotheken `PyTorch`, `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` und `Seaborn` verwenden. Nachfolgend importieren wir die benötigten Bibliotheken durch die Ausführung der folgenden Anweisungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rDvIKj-Ww1P"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, sys, urllib, io, warnings\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heUZY7dgWw1Q"
   },
   "source": [
    "Import der `PyTorch` Deep Learning Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RTb4Mc1Ww1Q"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning libary\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRpZfSImWw1R"
   },
   "source": [
    "Import der `sklearn` Bibliotheken bzw. Evaluationsmetriken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ180J4sWw1R"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tatoV81Ww1R"
   },
   "source": [
    "Import der `Matplotlib` und `Seaborn` Visualisierungs Bibliotheken und setzen der Visualisierungsparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTSNWwejWw1R"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausschalten möglicher Warnmeldungen z.B. aufgrund von zukünftigen Änderungen der Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the warning filter flag to ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g83bVkFrWw1S"
   },
   "source": [
    "Aktivieren der sog. Inline-Darstellung von Visualisierungen in Jupyter-Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0MKI98CWw1S"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importieren der `Colab GDrive` Bibliothek und einbinden unseres `GDrive` Laufwerks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I81E5iJOwR6x"
   },
   "source": [
    "Erstellen von Unterverzeichnissen innerhalb des aktuellen `GDrive`Arbeitsverzeichnisses für (1) die `GDrive` Notebooks im Allgemeinen, (2) das Speichern der Originaldaten und (3) der trainierten Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq5F-BV1wSXL"
   },
   "outputs": [],
   "source": [
    "# create Colab Notebooks directory\n",
    "notebook_directory = '/content/drive/MyDrive/Colab Notebooks'\n",
    "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
    "\n",
    " # create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/01_data'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    " # create models sub-directory inside the Colab Notebooks directory\n",
    "models_directory = '/content/drive/MyDrive/Colab Notebooks/02_models'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32BCRqyA5cD5"
   },
   "source": [
    "Festlegen eines zufälligen Seeds zur Gewährleistung der Reproduzierbarkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3cPTu1R5cmj"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value); # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHMs9Gf0wakv"
   },
   "source": [
    "Aktivieren des GPU Computing, durch setzen des `device` flag und setzen eines zufälligen `CUDA` Seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl2UHzshwdyk"
   },
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47HnxJHswf05"
   },
   "source": [
    "Anzeige der Hardware Informationen zu den ggf. verfügbaren GPU(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "907R1nhVwhXb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige der Software Informationen über die verfügbaren `Python` bzw. `PyTorch` Versionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current Python version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The Python version: {}'.format(now, sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current PyTorch version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyqnqndjWw1S"
   },
   "source": [
    "## 2. Datenakquise und Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgyKo34eWw1T"
   },
   "source": [
    "Der **Fashion-MNIST Datensatz** ist ein umfangreicher Datensatz mit Bildern zu Modeartikeln, die oftmals als Baseline für den Vergleich verschiedener Computer Vision Modelle verwendet wird. Zudem stellen die Bilder einen 'Hello World' Datensatz für das Trainieren und Testen von Deep Learning Klassifikatoren dar. Die Nachfolgenden Übersicht bietet einen Überblick über einige Beispielbilder des Datensatzes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q9TexBXWw1T"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: 300px\" src=\"https://github.com/HSG-AIML-Teaching/EMBA2022-Lab/blob/main/lab_04/FashionMNIST.png?raw=1\">\n",
    "\n",
    "(Quelle: https://www.kaggle.com/c/insar-fashion-mnist-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6cw9iEWw1T"
   },
   "source": [
    "Insgesamt umfasst der **Fashion-MNIST Datensatz** eine Grundgesamtheit von 70.000 Bildern.\n",
    "Der Datensatz unterteilt sich in **60.000 Trainingsbildern** und **10.000 Validierungsbilder**. Jedes Sample des Datensatzes stellt ein **28x28-Graustufenbild** dar, das gleichzeitg einem von **10 Klassenlabel** zugordnet ist. Insgesamt handelt es sich um einen balanzierten Datensatz, d.h. der Datensatz enthält für jede der 10 Bildklassen genau **6.000** Trainings- und **1.000** Valdierungsbeispiele. Das entsprechende Zalando GitHub Repository enthält zudem weitere Informationen über den Datensatz: [Zalando GitHub Page](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Download und Assessment der Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igSTsQMKWw1U"
   },
   "source": [
    "In einem ersten Schritt laden wir die Trainingsbilder des Datensatzes herunter. Dazu legen wir zunächst das Verzeichnis fest, in welchem wir die Trainingsdaten lokal speichern möchten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfCn1e8MWw1V"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + '/train_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4fUsNeLWw1V"
   },
   "source": [
    "Anschliessend beziehen wir die Trainingsdaten über die `TorchVision`Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-GZL31YWw1W"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_train_data = torchvision.datasets.FashionMNIST(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLuUXc4Ww1W"
   },
   "source": [
    "Nach erfolgreichem Download verfizieren wir die Anzahl der erhaltenen Trainingssamples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmRdyfxFWw1W"
   },
   "outputs": [],
   "source": [
    "# determine the number of training data images\n",
    "len(fashion_mnist_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtbIaCpLWw1W"
   },
   "source": [
    "Lassen Sie uns nun einige Beispiele der Trainingsbilder betrachten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAtYOeUPWw1X"
   },
   "outputs": [],
   "source": [
    "# select and set a (random) image id\n",
    "image_id = 42\n",
    "\n",
    "# retrieve image exhibiting the image id\n",
    "fashion_mnist_train_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfUMS402Ww1X"
   },
   "source": [
    "Ok, das scheint nicht geklappt zu haben. Trennen wir zunächst Bildinformationen von den Labelinformationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDzFFyZfWw1X"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_image, fashion_mnist_train_label = fashion_mnist_train_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SSorDiP_uFc"
   },
   "source": [
    "Wir können uns nun das Label des ausgewählten Bild ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weOc_Ceb_5dU"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctD4Dl0C_7RE"
   },
   "source": [
    "Nun wissen wir, dass unser ausgewähltes Bild das numerische Label 6 aufweist. Aber was bedeutet also dieses Label 6? \n",
    "\n",
    "Innerhalb des Datensatzes ist jedes Bild einem Label von 0 bis 9 zugordnet. Jeder dieser Zahlen steht für eine andere Klasse von Modeartikeln. Eine 'Übersetzung' der numerischen Label ist auf der [Zalando GitHub Page](https://github.com/zalandoresearch/fashion-mnist) zu finden. Nachfolgend definieren wir die sprechenden Übersetzungen der Labels als `Python` Dictionary, da wir sie später im Rahmen der Modelevaluation gerne verwenden möchten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmzSMz1FASrm"
   },
   "outputs": [],
   "source": [
    "fashion_classes = {0: 'T-shirt/top',\n",
    "                    1: 'Trouser',\n",
    "                    2: 'Pullover',\n",
    "                    3: 'Dress',\n",
    "                    4: 'Coat',\n",
    "                    5: 'Sandal',\n",
    "                    6: 'Shirt',\n",
    "                    7: 'Sneaker',\n",
    "                    8: 'Bag',\n",
    "                    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDvW1PUdKn3a"
   },
   "source": [
    "Uns ist es nun also möglich das Label in den Namen des Modeartikels umzuwandeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8KrM8rfKnHh"
   },
   "outputs": [],
   "source": [
    "fashion_classes[fashion_mnist_train_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JozKTGsCWw1X"
   },
   "source": [
    "Wunderbar, in einem nächsten Schritt möchten wir nun auch die zugehörigen Bildinformationen visualisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D80b3WkWWw1Y"
   },
   "outputs": [],
   "source": [
    "# define tensor to image transformation\n",
    "trans = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# set image plot title \n",
    "plt.title('Example: {}, Label: {}'.format(str(image_id), fashion_classes[fashion_mnist_train_label]))\n",
    "\n",
    "# plot mnist handwritten digit sample\n",
    "plt.imshow(trans(fashion_mnist_train_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download und Assessment der Evaluationsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5fmhiuzWw1Y"
   },
   "source": [
    "Dazu legen wir nun auch das Verzeichnis fest, in welchem wir die Evaluationsdaten lokal speichern möchten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G3eQFy3Ww1b"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNNTmyI7Ww1b"
   },
   "source": [
    "Anschliessend beziehen wir auch die Evaluationsdaten über die `TorchVision`Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvIBdhlPWw1b"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "# download and transform training images\n",
    "fashion_mnist_eval_data = torchvision.datasets.FashionMNIST(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4skfCFEfWw1c"
   },
   "source": [
    "Abschliessend verfizieren wir auch die erhaltenen Evaluationsdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq3rW2wKWw1c"
   },
   "outputs": [],
   "source": [
    "# determine the number of evaluation data images\n",
    "len(fashion_mnist_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucTxc7GGWw1c"
   },
   "source": [
    "## 3. Artificial Neural Network Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt möchten wir uns mit der zugrundeliegenden Idee und dem Aufbau eines tiefen **Artificial Neural Network (ANN)** vertraut zu machen. Hierzu werden wir die einzelne Bausteine und die spezifische Netzwerkstruktur von ANNs anhand der `PyTorch` Open-Source-Bibliothek implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyofP39KWw1d"
   },
   "source": [
    "### 3.1 Artificial Neural Network Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTQ_VZWaWw1d"
   },
   "source": [
    "Unsere Zielsetzung ist es ein **Artificial Neural Network** zu implementieren um Fashion-MNIST Bilder zu klassifizieren. Das ANN soll hierzu ein Modell zu lernen, dass die Bilder mit Umfang 28x28 Pixel entsprechend den Label der Klassen von Modeartikeln zuordnet. Bevor wir jedoch mit der Implementierung beginnen, wollen wir kurz nochmals den zu entwickelnden Prozess vor Augen führen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i5LlBmiWw1d"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 800px\" src=\"process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loUEinm1Ww1e"
   },
   "source": [
    "Wir möchten nun ein Artificial Neural Network implementieren, das wir **FashionMNISTNet** nennen. Das ANN soll aus drei Layern von jeweils **fully connected** künstlichen Neuronen bestehen. Zudem soll das **FashionMNISTNet** die folgende Anzahl von Neuronen pro Schicht enthalten: 100 Neuronen in der ersten Schicht, 50 Neuronen in der zweiten Schicht und 10 Neuronen in der dritten Schicht. Bitte beachten Sie, die Dimensionalität der Ausgabe an der dritten Schicht entspricht hierbei der Anzahl der Klassen des Fashion-MNIST Datensatzes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGxSr-77Ww1e"
   },
   "source": [
    "Die Implementierung von Netzwerkarchitekturen als **separate Klassen** in `PyTorch` ist gute Praxis im Rahmen von Deep-Learning-Projekten. Hierdurch ist es möglich mehrere Instanzen von Modellen mit identischer Netzwerkarchitektur zu erstellen und trainieren. Dies bietet uns zum Beispiel die Möglichkeit, verschiedene Initialisierungen der Netzwerkparameter zu bewerten oder Modelle mit unterschiedlichen Hyperparametern zu trainieren. Wir beginnen nun damit, die Netzwerkarchitektur zu implementieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLrELu2EWw1f"
   },
   "outputs": [],
   "source": [
    "# implement the MNISTNet network architecture\n",
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # specify fully-connected (fc) layer 1 - in 28*28, out 100\n",
    "        self.linear1 = nn.Linear(28*28, 100, bias=True) # the linearity W*x+b\n",
    "        self.relu1 = nn.ReLU(inplace=True) # the non-linearity \n",
    "        \n",
    "        # specify fc layer 2 - in 100, out 50\n",
    "        self.linear2 = nn.Linear(100, 50, bias=True) # the linearity W*x+b\n",
    "        self.relu2 = nn.ReLU(inplace=True) # the non-linarity\n",
    "        \n",
    "        # specify fc layer 3 - in 50, out 10\n",
    "        self.linear3 = nn.Linear(50, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = images.view(-1, 28*28)\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy63DaNzWw1f"
   },
   "source": [
    "Bei der Durchsicht der obigen Implementierung ist Ihnen vielleicht aufgefallen, dass wir innerhalb der dritten Schicht des Netzes eine bisher unbekannte Funktion verwendet haben, die als **Softmax** bezeichnet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Softmax Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die **Softmax-Funktion**, auch bekannt als *normalisierte Exponentialfunktion*, transformiert einen Vektor bestehend aus K rellen Zahlen in einen ebenfalls K-dimensionalen Vektor aus normalisierten Wahrscheinlichkeiten. Hierbei summieren sich die einzelnen Wahrscheinlichkeiten zu 1 auf. \n",
    "\n",
    "In unserem Beispiel ist es grds. möglicht, dass innerhalb des dritten Layer die einzelnen Vektorkomponenten einen negativen Wert oder Wert grösser als 1 aufweisen. Das hat zur Folge, dass die einzelnen Vektorkomponenten nicht unmittelbar als Wahrscheinlichkeiten für die verschiedenen Klassen des der Fashion-MNIST Datensatzes interpretiert werden können. Nach Anwendung der Softmax-Funktion ist eine solche Interpretation möglich. \n",
    "\n",
    "\n",
    "Im Allgemeinen ist die Softmax-Funktion $\\sigma :\\mathbb {R} ^{K}\\to \\mathbb {R} ^{K}$ anhand der nachfolgenden Formel definiert:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5s_1Q7NWw1f"
   },
   "source": [
    "<center> $\\sigma (\\mathbf {z} )_{i}=\\ln ({e^{z_{i}} / \\sum _{j=1}^{K}e^{z_{j}}})$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9JtxNu4Ww1f"
   },
   "source": [
    "für $i = 1, …, K$ und ${\\mathbf {z}}=(z_{1},\\ldots ,z_{K})\\in \\mathbb {R} ^{K}$ (Quelle: [Wikipedia](https://en.wikipedia.org/wiki/Softmax_function)). \n",
    "\n",
    "Schauen wir uns nun das nachfolgend Illustrierte Beispiel für die Klassifikation von drei Klassen an. Die Aktivität der Neuronen der dritten Schicht, vor der Softmax-Funktion, resultiert aus dem Forward-Pass des Netzes. Anhand der Softmax-Funktion wird diese Neuronanktivität in eine normalisierte Wahrscheinlichkeit pro Klasse $c_{i}$ umgewandelt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ULWQ3RmWw1f"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./softmax.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcrCZgZqWw1g"
   },
   "source": [
    "Die Softmax-Funktion beschreibt somit, mit welcher Wahrscheinlichkeit das ANN das zu klassifizierende Objekt einer bestimmten Klasse zuordnet. Für das erste Beispiel nihmt das erlernte Modell an, dass es sich mit 64% Wahrscheinlichkeit um ein Objekt der Klasse *Shirt* handelt, mit 4% Wahrscheinlichkeit um ein Objekt der Klasse *Trouser*, und mit 29% Wahrscheinlichkeit um ein Objekt der Klasse *Dress*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Modell Initialisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach erfolgreicher Implementierung unseres ersten ANNs, instanziieren wir nun ein Modell des `FashionMNIST` Netzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfvFFCCHWw1g"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efX9IOPSw8DZ"
   },
   "source": [
    "Anschliessend transferieren wir das Encoder Modell auf die `CPU` oder eine ggf. verfügbare `GPU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W93HbADVw8qe"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j5xBQ2yxAMw"
   },
   "source": [
    "Sofern verfügbar, prüfen wir ob das Modell erfolgreich auf die `GPU` übertragen wurde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFGVBXGgxAo5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yt4PtPLWw1g"
   },
   "source": [
    "Once the model is initialized, we can visualize the model structure and review the implemented network architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF90-Nk1Ww1g"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] FashionMNIST architecture:\\n\\n{}\\n'.format(now, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFKJMIjKWw1g"
   },
   "source": [
    "Abschliessend werfen wir noch einen Blick auf die Anzahl der Modellparameter, die wir im Folgenden beabsichtigen zu trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFOWHzJ3Ww1h"
   },
   "outputs": [],
   "source": [
    "# init the number of model parameters\n",
    "num_params = 0\n",
    "\n",
    "# iterate over the distinct parameters\n",
    "for param in model.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    num_params += param.numel()\n",
    "    \n",
    "# print the number of model paramters\n",
    "print('[LOG] Number of to be trained FashionMNISTNet model parameters: {}.'.format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9rZQ7JWw1h"
   },
   "source": [
    "Ok, unser ANN Modell umfasst eine beachtliche Gesamtzahl von **84.060 zu trainierenden Modellparametern**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pytnqULPWw1h"
   },
   "source": [
    "### 3.4 Fehlerfunktion Initialisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHpHWQ7JWw1h"
   },
   "source": [
    "Nach Implementierung des **FashionMNISTNet**, sind wir bereit ein entsprechendes Modell zu trainieren. Vor dem Training ist es jedoch zunächst notwendig eine geeignete Fehlerfunktion zu definieren. Grds. möchten wir anhand des Traininsprozesses Modellparameter $\\theta$ lernen, welche den Klassifizierungsfehler der wahren bzw. 'ground-truth' Klasse $c^{i}$ und der vorhergesagten Klasse $\\hat{c}^{i} = f_\\theta(x^{i})$ minimieren. \n",
    "\n",
    "Formal ausgedrückt besteht das Trainingsziel darin, Modellparameter $\\theta^*$ zu lernen, welche $\\arg\\min_{\\theta} \\|C - f_\\theta(X)\\|$ über alle Trainingsbilder des FashionMNIST-Datensatzes optimieren. Um das Trainingsziel zu erreichen, minimieren wir eine Fehlerfunktion $\\mathcal{L_{\\theta}}$ als Teil des Netzwerktrainings. Im Rahmen dieses Labs verwenden wir **'Negative Log Likelihood (NLL)'** Fehlerfunktion, die wie nachfolgend definiert ist:<br><br>\n",
    "\n",
    "<center> $\\mathcal{L}^{NLL}_{\\theta} (\\hat{c}_i) = - \\frac{1}{N} \\sum_{i=1}^N \\log (\\hat{c}_i) $, </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID9HqJJqWw1h"
   },
   "source": [
    "wobei $\\hat{c}^{i}$ die jeweilig durch das Modell vorhergesagten Klassen bezeichnet und $x^{i}$, $i=1,...,n$ die Menge der $n$ Fashion-MNIST Bilder $x^{i}$, $i=1,...,n$ eines Datensatzes bzw. Trainingsbatches. Werfen wir hierzu auch einen Blick auf ein kurzes Beispiel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xRWCsbrWw1i"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 800px\" src=\"./loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcObuMZfWw1i"
   },
   "source": [
    "Während des Trainings 'bestraft' die **NLL** Fehlerfunktion Modelleparameter, die zu einem hohen Klassifikationsfehler führen. Nachfolgend instanzieren wir die entsprechende **NLL** Fehlerfunktion der `PyTorch` Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbgFFIDjWw1i"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbspDM2dxGrO"
   },
   "source": [
    "Anschliessend transferieren wir die Berchnung der Fehlerfunktion auf die `CPU` oder eine ggf. verfügbare `GPU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgKeoEcaxIdB"
   },
   "outputs": [],
   "source": [
    "nll_loss = nll_loss.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJhKTaHnWw1i"
   },
   "source": [
    "## 4. Artificial Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRwd3R8XWw1i"
   },
   "source": [
    "In diesem Abschnitt möchten wir nun ein ANN-Modell anhand der Fashion-MNIST Trainingsbilder trainieren. Darüber hinaus werfen wir einen detaillierten Blick auf die einzelnen Trainingshyperparameter und Trainingsschritte sowie den Trainingsfortschritt im Zeitverlauf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbH8GgrWw1i"
   },
   "source": [
    "### 4.1 Definition der Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K23pmmEWw1j"
   },
   "source": [
    "Beginnen wir nun damit, ein ANN Modell für **20 Trainingsepochen** und **128 Fashion-MNIST Bildern pro Mini-Batch** zu trainieren. Diese Konfiguration der Hyperparameter bedeutet, dass der Datensatz dem ANN insgesamt zwanzig mal in Mini-Batches von 128 jeweils Bildern zugeführt wird. Diese Hyperparameter Konfiguration hat zu Folge, dass pro Trainingsepoche **469 Updates** (60.000 Buchungen modulo 128 Bilder pro Mini-Batch) der ANN Modellparameter erfolgen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bMEnxc1Ww1j"
   },
   "outputs": [],
   "source": [
    "# specify the training parameters\n",
    "num_epochs = 20 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX99_DY7Ww1j"
   },
   "source": [
    "Auf der Grundlage der Fehlerhöhe eines Mini-Batches berechnet die `PyTorch` Bibliothek automatisiert die Gradienten. Anschliessend werden ANN-Parameter $\\theta$ auf Grundlage der ermittelten Gradienten optimiert. Hierzu ist es lediglich notwendig ein gewünschtes Optimierungsverfahren in **PyTorch** zu definieren. In der nachfolgenden Notebook Zelle verwenden wir das im Seminar besprochene **Stochastic Gradient Descent** Verfahren für die Optimierung der Modellparameter $\\theta$. Darüber hinaus definieren wir eine eine Lernrate $l = 0.001$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84Oq2woEWw1j"
   },
   "outputs": [],
   "source": [
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO1P2wb3Ww1k"
   },
   "source": [
    "Während der Trainingsphase sollen dem ANN Modell kontinuierlich Mini-Batches der gesamten Trainingsbilder Population zugeführt werden. Hierzu verwenden wir die `DataLoader` Funktionalität der `PyTorch` Bibliothek. Dabei handelt es sich im sog. Iteratoren, welche die Bilder kontinuierlich in Form von Mini-Batches zur Verfügung stellen. In der nachfolgenden Zelle instanzieren wir einen `PyTorch` Dataloader der Trainingsbilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyLwFEMXWw1l"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(fashion_mnist_train_data, batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir die verschiedenen Bausteine des ANN-Modells erfolgreich implementiert und instanziiert haben. Nehmen wir uns Zeit, die Definition des **FashionMNISTNet** als auch die **NLL-Fehlerfunktion** nochmals zu überprüfen und etwaige Fragen zu besprechen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp6hmrg7Ww1l"
   },
   "source": [
    "### 4.2 Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov5Z6NLvWw1m"
   },
   "source": [
    "Nach Definition der Hyperparameter können wir mit dem Training des Modells beginnen. Für jeden zugeführten Mini-Batch werden im Rahmen des Trainingsprozesses die nachfolgenden Schritte ausgeführt: \n",
    "\n",
    ">1. Durchführung des Forwardpass durch das FashionMNISTNet.\n",
    ">2. Berechnen des NLL-Rekonstruktionsfehlers $\\mathcal{L^{NLL}_{\\theta}}(x^{i};\\hat{x}^{i})$.\n",
    ">3. Durchführung des Backwardpass durch das FashionMNISTNet.\n",
    ">4. Update der Netzwerk Parameter $f_\\theta(\\cdot)$.\n",
    "\n",
    "Um das Lernen während des Trainings zu gewährleisten, beobachten wir den NLL Rekonstruktionsfehler des ANN-Modells mit fortschreitendem Training. Durch diese Beobachtung ist es möglich auf den Lernfortschritt des Modells zu schliessen. Darüber hinaus kann festgestellt werden, ob bzw. wann der NLL-Fehler konvergiert.\n",
    "\n",
    "Im Rahmen der Modelloptimierung möchten wir den nachfolgenden `PyTorch`Anweisungen eine besondere Beachtung schenken:\n",
    "\n",
    ">- `loss.backward()` Berechnung die Gradienten auf der Grundlage des NLL-Fehlers.\n",
    ">- `optimizer.step()` Aktualisierung der Parameter auf Grundlage der Gradienten.\n",
    "\n",
    "Nach jeder abgeschlossenen Trainingsepoche möchten wir zudem einen sog. **Modell Checkpoint** speichern. Die Checkpoints enthalten eine Bestandsaufnahme bzw. 'Schnappschuss' der Modellparameter. Im Allgemeinen ist es eine gute Praxis, während des Trainings solche Checkpoints in regelmässigen Abständen zu speichen. Sollte das Training einmal unterbrochen werden, kann es beginnend auf dem letzten Checkpoint wieder fortgesetzt werden. Für das Speichern eines Modell Checkpoints verwenden wir die nachfolgende `PyTorch` Anweisung:\n",
    "\n",
    ">- `torch.save()`: speichert den Checkpoint der aktuellen Modellparameterwerte auf dem lokalen Dateisystem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70W8AZWlWw1m"
   },
   "outputs": [],
   "source": [
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the MNISTNet model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "        \n",
    "        # push mini-batch data to computation device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = dt.datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # set filename of actual model\n",
    "    model_name = 'fashion_mnist_model_epoch_{}.pth'.format(str(epoch))\n",
    "\n",
    "    # save current model to GDrive models directory\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dqoGo_7Ww1m"
   },
   "source": [
    "In einem nächsten Schritt visualisieren wir den jeweiligen NLL-Fehler für jede Trainingsepoche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLI0Y53VWw1m"
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"[Training Epoch $e_i$]\", fontsize=10)\n",
    "ax.set_ylabel(\"[Classification Error $\\mathcal{L}^{NLL}$]\", fontsize=10)\n",
    "\n",
    "# set plot legend\n",
    "plt.legend(loc=\"upper right\", numpoints=1, fancybox=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title('Training Epochs $e_i$ vs. Classification Error $L^{NLL}$', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmkQMB6YWw1n"
   },
   "source": [
    "Es ist zu beobachten, dass der NLL-Fehler des ANN Models nach fünf Epochen kontinuierlich zu sinken beginnt. Diese Beobachtung impliziert, dass es dem Modell sukzessive gelingt die innerhalb des Datensatzes enthaltenen Bilder korrekt zu klassifizieren. Anhand der Visualisierung wird jedoch auch deutlich, dass das Modell noch einige Epochen weiter trainiert werden könnte bis der NLL-Fehler nicht mehr sinkt bzw. konvergiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nyWq1X-Ww1n"
   },
   "source": [
    "## 5. Artificial Neural Network Modell Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt möchten wir die Fähigkeit des erlernten ANN Modells zur Klassifikation von Fashion-MNIST Bilder evaluieren. Hierzu werden wir auf vortrainierte ANN Modelle zurück greifen. Die Evaluation umfasst die 10.000 Evaluationsbilde des Fashion-MNIST Datensatzes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Laden eines Modell Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7-GBxuwWw1n"
   },
   "source": [
    "Für die Evaluation laden wir üblicherweise das ANN-Modell mit **geringstem NLL-Fehler** oder verwenden ein anderes, d.h. bereits vortrainiertes, Modell. Im Rahmen des Trainings hatten wir pro Epoche jeweils ein Checkpoint der Modellparameter innerhalb des lokalen Modellverzeichnis gespeichert. Wir werden nun einen bereits für **20 Trainingsepochen** trainierten Modell Checkpoint laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-w1B1k_NWw1n"
   },
   "outputs": [],
   "source": [
    "# restore pre-trained model snapshot\n",
    "best_model_name = 'https://raw.githubusercontent.com/GitiHubi/CADS/main/lab_04/03_models/fashion_mnist_model_epoch_19.pth'\n",
    "\n",
    "# read stored model from the remote location\n",
    "model_bytes = urllib.request.urlopen(best_model_name)\n",
    "\n",
    "# load model tensor from io.BytesIO object\n",
    "model_buffer = io.BytesIO(model_bytes.read())\n",
    "\n",
    "# init pre-trained model class\n",
    "best_model = FashionMNISTNet()\n",
    "\n",
    "# load pre-trained models\n",
    "best_model.load_state_dict(torch.load(model_buffer, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oqOeiajWw1n"
   },
   "source": [
    "Nun können wir die Modellstruktur visualisieren und die Netzarchitektur nochmals durch das Ausführen der folgenden Zelle überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KarjZ3ldWw1n"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] FashionMNIST architecture:\\n\\n{}\\n'.format(now, best_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darüber hinaus setzen wir das geladene Modell in den Evaluationsmodus. Das versetzen in den Evaluationsmodus stellt sicher, dass etwaige Trainingsfunktion, z.B. Regularisierungen wie *Dropout* oder *Batch Normalization*, ausgeschaltet sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model in evaluation mode\n",
    "best_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluation des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaFA9LyRWw1o"
   },
   "source": [
    "To evaluate our trained model, we need to feed the FashionMNIST images reserved for evaluation (the images that we didn't use as part of the training process) through the model. Therefore, let's again define a corresponding PyTorch data loader that feeds the image tensors to our neural network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQB-RFR8Ww1o"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_eval_dataloader = torch.utils.data.DataLoader(fashion_mnist_eval_data, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPP7OowBWw1o"
   },
   "source": [
    "In einem nächsten Schritt berechnen wir den durchschnittlichen **NLL Fehler** für jeden Mini-Batch der Evaluationsbilder des Fashion-MNIST Datensatzes. Dieser Fehlerwert ermöglicht es uns Rückschlüsse für ein etwaiges **Overfitting** des Modells zu ziehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpttWy_AWw1o"
   },
   "outputs": [],
   "source": [
    "# init collection of mini-batch losses\n",
    "eval_mini_batch_losses = []\n",
    "\n",
    "# iterate over all-mini batches\n",
    "for i, (images, labels) in enumerate(fashion_mnist_eval_dataloader):\n",
    "\n",
    "    # run forward pass through the network\n",
    "    output = best_model(images)\n",
    "\n",
    "    # determine classification loss\n",
    "    loss = nll_loss(output, labels)\n",
    "\n",
    "    # collect mini-batch reconstruction loss\n",
    "    eval_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "# determine mean min-batch loss of epoch\n",
    "eval_loss = np.mean(eval_mini_batch_losses)\n",
    "\n",
    "# print epoch loss\n",
    "now = dt.datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] eval-loss: {}'.format(str(now), str(eval_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNwLBDGPWw1p"
   },
   "source": [
    "Okay, der durchschnittliche **NLL-Fehler** scheint einem ähnlichen Werterbereich wie der letzte Trainingsfehler des Modells zu liegen. Hierdurch ist ein etwaiges **Overfitting** auf den Trainingsdaten unwahrscheinlich. \n",
    "\n",
    "Um einen Eindruck von der Qualität des Modells zu erhalten, schauen wir uns nun ein paar beispielhafte Klassifikationen an. Hierzu wählen wir ein zufälliges Bild der Evaluationsdaten aus um den den entsprechenden `PyTorch` Tensor sowie das korrespondierende Label zu erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTM5mTHaWw1p"
   },
   "outputs": [],
   "source": [
    "# set (random) image id\n",
    "image_id = 2000\n",
    "\n",
    "# retrieve image exhibiting the image id\n",
    "fashion_mnist_eval_image, fashion_mnist_eval_label = fashion_mnist_eval_data[image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkZowxdUWw1p"
   },
   "source": [
    "In einem ersten Schritt extrahieren wir das **ground-truth** Label des Bildes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIq9uSnfWw1q"
   },
   "outputs": [],
   "source": [
    "fashion_classes[fashion_mnist_eval_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjz4GOpyWw1q"
   },
   "source": [
    "Ok, das ausgewählte Bild soll eine Tasche enthalten. Lassen Sie uns das Bild nun visualiseren und anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1hZMQ6oWw1r"
   },
   "outputs": [],
   "source": [
    "# define tensor to image transformation\n",
    "trans = torchvision.transforms.ToPILImage()\n",
    "\n",
    "# set image plot title \n",
    "plt.title('Example: {}, Label: {}'.format(str(image_id), fashion_classes[fashion_mnist_eval_label]))\n",
    "\n",
    "# plot mnist handwritten digit sample\n",
    "plt.imshow(trans(fashion_mnist_eval_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFW-PYEnWw1r"
   },
   "source": [
    "In einem zweiten Schritt möchten wir nun die **Klassifikation** des Bildes durch das Modell erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfaV80IpWw1s"
   },
   "outputs": [],
   "source": [
    "# determine model prediction\n",
    "prediction = best_model(fashion_mnist_eval_image)\n",
    "\n",
    "# print the model prediction\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNFAM_deWw1s"
   },
   "source": [
    "Anschliessend bestimmen wir die vorhergesagte Klasse des Klassifikationsergebnisses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2knLiUqWw1t"
   },
   "outputs": [],
   "source": [
    "# determine most probable class\n",
    "most_probable = torch.argmax(prediction, dim=1).item()\n",
    "\n",
    "# print the classification result\n",
    "print('Most probable class label: {}'.format(most_probable))\n",
    "print('The label corresponds to the following fashion article: {}'.format(fashion_classes[most_probable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwOIf2adWw1t"
   },
   "source": [
    "Um eine Aussage über die Qualität des gelernten Modells zu treffen, klassifizieren wir nun alle 10.000 Bilder des Trainingsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRmjfYDZWw1t"
   },
   "outputs": [],
   "source": [
    "predictions = torch.argmax(best_model(fashion_mnist_eval_data.data.float()), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFKiMKw-Ww1t"
   },
   "source": [
    "Auf Grundlage der Klassifikationen bestimmen wir nun die **Acurracy** des Modells über alle Klassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvV-HLcsWw1t"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(fashion_mnist_eval_data.targets, predictions.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B-KdgKNWw1u"
   },
   "source": [
    "Lassen Sie uns auch einen Blick auf die zugehörige **Confusion-Matrix** werfen um die Quellen der Fehlklassifikationen zu ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5LkSBwpWw1u"
   },
   "outputs": [],
   "source": [
    "# determine classification matrix of the predicted and target classes\n",
    "mat = confusion_matrix(fashion_mnist_eval_data.targets, predictions.detach())\n",
    "\n",
    "# initialize the plot and define size\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# plot corresponding confusion matrix\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='YlOrRd_r', xticklabels=fashion_classes.values(), yticklabels=fashion_classes.values())\n",
    "plt.tick_params(axis='both', which='major', labelsize=8, labelbottom = False, bottom=False, top = False, left = False, labeltop=True)\n",
    "\n",
    "# set plot title\n",
    "plt.title('Fashion MNIST classification matrix')\n",
    "\n",
    "# set axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob6vR-e3Ww1u"
   },
   "source": [
    "Auf Grundlage der **Confusion-Matrix** wird deutlich, dass unser derzeitiges Modell beispielsweise die Klasse **Sneaker** mit der Klasse **Sandal** verwechselt. Eine ebenfalls hohe Fehlerquelle lässt sich für die Klassen **Shirt** und **Coat** beobachten. Diese Fehler sind nicht sehr überraschend, da die Form der Artikel innerhal der Trainingsbilder eine grosse Ähnlichkeit aufweisen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Ihr wissen zu vertiefen empfehlen wir, die nachfolgenden Übungen zu bearbeiten:\n",
    "\n",
    "**1. Trainieren Sie das ANN Modell für weniger bzw. mehr Epochen und evaluieren Sie die Vorhersagegenauigkeit.**\n",
    "\n",
    "> Reduzieren bzw. erhöhen Sie die Anzahl der Trainingsepochen auf **5 Epochen bzw. 100 Epochen** und führen Sie das Modelltraining jeweils erneut durch. Laden und bewerten Sie jeweils  Modell, das den geringsten NLL-Fehler aufweist. Welches Verhalten ist in Bezug auf die Vorhersagegenauigkeit durch die Veränderung der Anzahl der Trainingsepochen zu beobachten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Analyse von `shallow` bzw. `deep` Neuronalen Netz Modellen.**\n",
    "\n",
    "> Evaluieren Sie weitere `shallow` bzw. `deep` Architekturen Neuronaler Netze. Variieren Sie hierzu wahlweise (1) die **Anzahl Schichten** oder (2) die **Anzahl Neuronen** der Architektur. Trainieren Sie für jede Änderung jeweils ein Modell für mindestens 40 Epochen. Analysieren Sie die unterschiedlichen Modelle im Hinblick auf ihre jeweilige Anzahl Parameter und die Accuracy auf den Evaluationsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1l8HbUzWw1v"
   },
   "source": [
    "## Lab Zusammenfassung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3P5e48aWw1w"
   },
   "source": [
    "Dieses Notebook umfasste eine schrittweise Einführung in den **Entwurf, die Implementierung, das Training und die Auswertung** von neuronalen Netzen zur Klassifizierung von Bildern. Die vorgestellten Code Beispiele und die Übungen können als Ausgangspunkt für die Entwicklung komplexerer, tieferer und maßgeschneiderter **Neuronaler Netze** dienen."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aut1dJXmWw1O",
    "Ks081EJEWw1P",
    "vyqnqndjWw1S",
    "ucTxc7GGWw1c",
    "hJhKTaHnWw1i",
    "8nyWq1X-Ww1n",
    "e1l8HbUzWw1v"
   ],
   "name": "lab_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
