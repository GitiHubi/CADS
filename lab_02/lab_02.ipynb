{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGwNwDKEt8lG"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"./fs_logo.png\">\n",
    "\n",
    "##  Lab 02 - Supervised Machine Learning\n",
    "\n",
    "Seminar Künstliche Intelligenz, Frankfurt School, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analysen des Seminars **Künstliche Intelligenz** des Zertifikatstudiengangs **Certified Audit Data Scientist (CADS)** basieren auf Jupyter Notebook. Anhand solcher Notebooks ist es möglich eine Vielzahl von Datenanalysen und statistischen Validierungen durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./lab_02_banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYpS4wEPt8lI"
   },
   "source": [
    "Im letzten Lab haben Sie verschiedene Elemente der Python-Programmierung kennengelernt, z.B. Bedingungen, Schleifen und die Implementierung von Funktionen usw. In diesem dritten Lab werden wir unseren ersten **Supervised Machine Learning** Workflow mit dem in der Vorlesung vorgestellten **k Nearest-Neighbors (kNN)** Algorithmus erstellen.\n",
    "\n",
    "Der *diskriminative* **k Nearest-Neighbors (kNN)**-Klassifikator ist ein einfacher, vielseitiger und leistungsstarker Algorithmus für das maschinelle Lernen. Bis vor kurzem, d.h. vor dem Aufkommen von Deep-Learning-Ansätzen, wurde er in einer Vielzahl von Anwendungen eingesetzt, z. B. im Finanzwesen für die Kreditwürdigkeitsprüfung oder der Paleographie zur Erkennung von Handschriften. \n",
    "\n",
    "Wir werden den **k Nearest-Neighbors (kNN)**-Klassifikator dazu verwenden, um zu lernen, Beobachtungen des **Iris Datensatzes** zu klassifizieren. Die folgende Abbildung zeigt einen Überblick über den Prozess des maschinellen Lernens, welchen wir in diesem Notebook erstellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMdudNYut8lJ"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"./splash.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Br5f8mEt8lK"
   },
   "source": [
    "Bei etwaigen Fragen wenden Sie sich, wie immer gerne an uns via **marco (dot) schreyer (at) unisg (dot) ch**. Wir wünschen Ihnen Viel Freude mit unseren Notebooks und Ihren revisorischen Analysen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0Jnx-Ljt8lK"
   },
   "source": [
    "## Lernziele des Labs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybF-i5mQt8lL"
   },
   "source": [
    "Nach der heutigen Übung sollten Sie in der Lage sein:\n",
    "\n",
    "> 1. Den **Supervised Machine Learning** Workflow in Form eines Notebook zu erstellen.\n",
    "> 2. Die Datengrundgesamtheiten für das **Trainieren** und **Bewerten** eines Klassifikators zu unterscheiden. \n",
    "> 3. Den **k Nearest-Neighbors (kNN)** Klassifikator zu trainieren und zu evaluieren.\n",
    "> 4. Die Python **sklearn Bibliothek** zu verwenden, um beliebige Klassifikatoren zu trainieren bzw. zu optimieren.\n",
    "> 5. Die **gewonnenen Ergebnisse** eines Klassifikators auszuwerten und zu interpretieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZaa0qAnt8lY"
   },
   "source": [
    "## 1. Einrichten der Anlyseumgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yTCqemyt8la"
   },
   "source": [
    "Ähnlich wie in den vorangegangenen Übungen müssen wir eine Reihe von Python-Bibliotheken importieren, die Datenanalyse und -visualisierung ermöglichen. In dieser Übung werden wir die Bibliotheken `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` und `Seaborn` verwenden. Nachfolgend importieren wir die benötigten Bibliotheken durch die Ausführung der folgenden Anweisungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "o3ShseCwt8lb",
    "outputId": "1254c7ff-5876-4508-8fde-5528e4d704f3"
   },
   "outputs": [],
   "source": [
    "# import the numpy, scipy and pandas data science library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import sklearn data and data pre-processing libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import k-nearest neighbor classifier library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# import matplotlib data visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFnbcu4yt8le"
   },
   "source": [
    "Aktivieren der sog. Inline-Darstellung von Visualisierungen in Jupyter-Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLbxWoZit8lf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsFqwDkYt8ln"
   },
   "source": [
    "Verwenden des `Seaborn` Visualisierungstil's in allen nachfolgenden Visualisierungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMH7Y9-Ht8lo"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Z2tRqzFt8lu"
   },
   "source": [
    "Festlegen eines zufälligen Seeds zur Gewährleistung der Reproduzierbarkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzE1FzaSt8lu"
   },
   "outputs": [],
   "source": [
    "random_seed = 2222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMSfpCPvt8l4"
   },
   "source": [
    "## 2. Datenakquise und Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0gpZzk5t8l5"
   },
   "source": [
    "### 2.1 Datensatz Download und Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cilrWTyMt8l6"
   },
   "source": [
    "Der **Iris-Datensatz** ist ein klassischer und einfacher Datensatz, der oft als \"Hello World\"-Beispiel in der Mehrklassen-Klassifikation verwendet wird. Dieser Datensatz besteht aus Messungen von drei verschiedenen Arten von Irisblüten (als **Klassen** bezeichnet), nämlich der Iris Setosa, der Iris Versicolour und der Iris Virginica, und ihrer jeweiligen gemessenen Blütenblatt- und Kelchblattlänge (als **Merkmale** bezeichnet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlF-VYuOt8l7"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: auto\" src=\"iris_dataset.png\">\n",
    "\n",
    "(Quelle: http://www.lac.inpe.br/~rafael.santos/Docs/R/CAP394/WholeStory-Iris.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBHv_Rbrt8l8"
   },
   "source": [
    "Insgesamt besteht der Datensatz aus **150 Samples** (50 Samples pro Klasse) sowie den entsprechenden **4 verschiedenen Features**, die für jede Probe durchgeführt wurden. Nachfolgend, die Liste der einzelnen Features:\n",
    "\n",
    ">- `Sepal length (cm)`\n",
    ">- `Sepal width (cm)`\n",
    ">- `Petal length (cm)`\n",
    ">- `Petal width (cm)`\n",
    "\n",
    "Further details of the dataset can be obtained from the following puplication: *Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).\"*\n",
    "\n",
    "Laden wir nun den Datensatz und führen wir ein erstes Assessment der erhaltenen Daten durch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CtBrJGut8l9"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AE2PbwClt8mB"
   },
   "source": [
    "Ausgabe und Prüfen der vier im Datensatz enthaltenen Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "NzLzNDo8t8mF",
    "outputId": "e336addc-0032-4f19-c65b-83a4482bc4a5"
   },
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIvnl8Qct8mK"
   },
   "source": [
    "Ausgabe und Prüfen der Feature-Dimensionalität des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tq6gZN-1t8mM",
    "outputId": "8c985d93-12bb-4b17-e45d-6f284cedb17a"
   },
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwiIRMR_t8mW"
   },
   "source": [
    "Ausgabe und Prüfen der Label-Dimensionalität des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tayVqRQOt8mX",
    "outputId": "1ec43974-51bb-4117-e0e9-de84b82676bc"
   },
   "outputs": [],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoQlbXs_t8md"
   },
   "source": [
    "Ausgabe und Prüfen der im Datensatz enthaltenen Klassen Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "R__ACqSct8me",
    "outputId": "f257226b-e22b-441c-db4a-50e47c9dad6c"
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwqoNt8gt8mh"
   },
   "source": [
    "Let's briefly envision how the feature information of the dataset is collected and presented in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCgJtdiot8mi"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"./feature_collection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rD3SBLxzt8mi"
   },
   "source": [
    "Ausgabe und Inspektion der ersten fünf Featurezeilen des Iris-Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "kju1z4Cft8mk",
    "outputId": "cf9f8028-e60b-4acf-dfd1-c6b2aaed1ddd"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris.data, columns=iris.feature_names).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P62AsvZ8t8mr"
   },
   "source": [
    "Ausgabe und Inspektion der korrespondierenden Labels der ersten fünf Featurezeilen des Iris-Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "oNjr0a5Dt8ms",
    "outputId": "160bca1e-1408-4904-efec-04a3a8939d97"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris.target, columns=[\"class\"]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fxz--vVdt8mu"
   },
   "source": [
    "Im Folgenden, führen wir nun eine eingehendere Bewertung der Daten durch. Dazu visualisieren wir die Merkmalsverteilungen des Iris-Datensatzes entsprechend ihrer jeweiligen Klassenzugehörigkeit sowie die paarweisen Beziehungen der Merkmale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWofkTgQt8mw"
   },
   "source": [
    "Wir verwenden die Python-Bibliothek **Seaborn**, um eine solche Visualisierung zu erstellen, die auch als **Pairplot** bezeichnet wird. Die Seaborn Bibliothek ist eine leistungsstarke Datenvisualisierungsbibliothek, die auf der Matplotlib basiert. Sie bietet eine hervorragende Schnittstelle zum Zeichnen informativer statistischer Grafiken (https://seaborn.pydata.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "JmfO2-yit8mx",
    "outputId": "6a2392f8-a12e-4360-a5a8-acdf6bc9970d"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# load the dataset also available in seaborn\n",
    "iris_plot = sns.load_dataset(\"iris\")\n",
    "\n",
    "# plot a pairplot of the distinct feature distributions\n",
    "sns.pairplot(iris_plot, diag_kind='hist', hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ugPoMiQt8m4"
   },
   "source": [
    "Aus dem erstellten Pairplot ist ersichtlich, dass die meisten Features, die der Blütenklasse `setosa` entsprechen, eine **lineare Trennbarkeit** von den Features der übrigen Blütenklassen aufweisen. Darüber hinaus weisen die Blütenklassen `versicolor` und `virginica` eine **nicht lineare Trennbarkeit** über alle gemessenen Features des Iris-Datensatzes auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgRYuUMKt8rL"
   },
   "source": [
    "### 2.3 Feature Skalierung des Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVzLw8uot8rL"
   },
   "source": [
    "Betrachtet man die Featurewerte des **Iris-Datensatzes**, so stellt man fest, dass die jeweiligen Wertebereiche stark variieren. Dies stellt eine Herausforderung für abstandsbasierte Algorithmen wie den **k Nearest-Neighbors** Klassifikator dar. Solche Algorithmen berechnen den Abstand zwischen zwei Samples anhand eines Abstandsmaßes wie z.B. dem **Euklidischen** oder **Manhattan** Abstand.\n",
    "\n",
    "Weist eines dieser Merkmale einen großen Wertebereich auf, dominiert der berechnete Abstand dieses speziellen Features die Funktion des Algorithmnus. Deshalb ist es notwendig den Wertebereich der verschiedenen Features zu skalieren, z.B. auf einen Wertebereich zwischen $[0,1]$ oder $[-1,1]$. Hierdurch ist gewährleistet, dass jedes Feature gleichwertig zum Ergebnis des Algorithmus beiträgt. Ein verbreitetes Verfahren zur Skalierung von Merkmalen wird als **Min-Max-Normalisierung** bezeichnet und ist durch folgende Formel definiert:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6jo00Alt8rL"
   },
   "source": [
    "$$x'={\\frac  {x-{\\text{min}}(x)}{{\\text{max}}(x)-{\\text{min}}(x)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bo6ERPyUt8rL"
   },
   "source": [
    "Skalieren wir nun die einzelnen Featurewerte des **Wein-Datensatzes** anhand der **Min-Max-Normalisierung** unter Verwendung der `MinMaxScaler` Funktionalität der `sklearn` Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ccNkX14Vt8rM"
   },
   "outputs": [],
   "source": [
    "# init the min-max scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "\n",
    "# min-max normalize the distinct feature values\n",
    "iris_data_norm = scaler.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsWFNsVTt8rS"
   },
   "source": [
    "Ausgabe und Prüfen der ersten 5 Merkmalszeilen des normalisierten Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "1cqcjpJZt8rT",
    "outputId": "be595c68-b074-41ee-f57a-d1846b3f63d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris_data_norm, columns=iris.feature_names).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3GbEr0jt8rX"
   },
   "source": [
    "Wir können nun feststellen, dass die Merkmalswerte min-max skaliert wurden. Lassen Sie uns diese Beobachtung nun auch kurz statistisch validieren, d.h. um zu prüfen ob tatsächlich alle Merkmalswerte auf einen Wertebereich zwischen $[0,1]$ skaliert wurden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "MzFsjejPt8rX",
    "outputId": "20aebe50-91d7-4c7f-8cf4-30a2340558d2"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(iris_data_norm, columns=iris.feature_names).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHwTTkWxt8rY"
   },
   "source": [
    "Das Ergebnis schaut gut aus, d.h. alle Merkmalswerte liegen tatsächlich in einem Bereich zwischen $[0,1]$. Nachfolgend möchten wir das Ergebnis der neu skalierten Features auch einmal visuell analysieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 992
    },
    "colab_type": "code",
    "id": "UGDK8Me3t8rZ",
    "outputId": "3af54c21-3275-41d9-f7b2-5484669fd9aa"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# prepare the dataset to be plotable using seaborn\n",
    "\n",
    "# convert to Panda's DataFrame\n",
    "iris_plot = pd.DataFrame(iris_data_norm, columns=iris.feature_names)\n",
    "\n",
    "# add class labels to the DataFrame\n",
    "iris_plot['class'] = iris.target\n",
    "\n",
    "# plot a pairplot of the distinct feature distributions\n",
    "sns.pairplot(iris_plot, diag_kind='hist', hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7PF3yj1t8ra"
   },
   "source": [
    "Hervorragend, die verschiedenen Verteilungen der Merkmale blieben unverändert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTWFzhhFt8m4"
   },
   "source": [
    "### 2.3 Training-Evaluation Split des Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTBwny8Dt8m5"
   },
   "source": [
    "Um die Qualität eines trainierten Modells des **überwachten maschinellen Lernens** zu verstehen und zu bewerten, empfiehlt es sich, den Datensatz in einen **Trainingsdatensatz** (der Teil der Datensätze, der ausschließlich zu Trainingszwecken verwendet wird) und eine **Evaluationsdatensatz** (der Teil der Datensätze, der ausschließlich zu Evaluierungszwecken verwendet wird) zu unterteilen. Der **Evaluationsdatensatz** wird dem Modell im Rahmen des Trainingsprozesses nicht gezeigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFU5ijYat8m6"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 500px; height: auto\" src=\"./train_eval_dataset.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YN25KKcvt8m6"
   },
   "source": [
    "Im Folgenden definieren wir **30%** des ursprünglichen Datensatzes als Evaluationsdatensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPFvlzS6t8m7"
   },
   "outputs": [],
   "source": [
    "eval_fraction = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FkQME8Ut8m9"
   },
   "source": [
    "Randomly split the dataset into training set and evaluation set using sklearn's `train_test_split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xF7m6KMSt8m9"
   },
   "outputs": [],
   "source": [
    "# 70% training and 30% evaluation\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(iris_data_norm, iris.target, test_size=eval_fraction, random_state=2222, stratify=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T37IuZHIt8m_"
   },
   "source": [
    "Ausgabe und Prüfen der Feature- und Label-Dimensionalität des Trainingsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "N9i0U2uzt8nA",
    "outputId": "65cba01c-5c0e-4e75-e66d-e92cbdff8e29"
   },
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqJitVsit8nC"
   },
   "source": [
    "Ausgabe und Prüfen der Feature- und Label-Dimensionalität des Evaluationsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "XeVTeCNat8nD",
    "outputId": "b96516ef-10af-4216-abfa-b7a3e4810631"
   },
   "outputs": [],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9HtRmw-t8nJ"
   },
   "source": [
    "## 3. k Nearest-Neighbor (kNN) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ns_yibVst8nK"
   },
   "source": [
    "Ein beliebter (und bemerkenswert einfacher) Algorithmus ist der **k Nearest-Neighbors (kNN)** Algorithmus. Im Ergebnis liefert das Verfahren für jedes unbekannte Sample $x$ eine Klassenzugehörigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 800px; height: auto\" src=\"./knn_algorithm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir den k Nearst-Neighbors zu Klassifikation eines Samples $x$ des Iris-Datensatzes anwenden schauen wir uns nochmals die einzelnen Schritte des Algorithmus an. Dabei gehen wir zunächst von folgenden Annahmen aus:\n",
    "\n",
    "- Trainingsdatensatz $D$ bestehend aus Datensätzen $D=\\{(x_1,y_1), (x_2, y_2), (x_3, y_3), ..., (x_n, y_n)\\} \\in \\mathcal{R}^d$; \n",
    "- Verschiedene Klassen-Labels $C$, wobei $y_1$, $y_2$, …, $y_n$ $\\in \\{1, 2, …, C\\}$.\n",
    "- Durch den k Nearst-Neighbors Algorithmus zu klassifizierendes Sample $x \\in \\mathcal{R}^d$ . \n",
    "\n",
    "Basierend auf diesen Annahmen ist es möglich die nachfolgenden Schritte des **k Nearst-Neighbors**-Algorithmus durchzuführen:\n",
    "\n",
    ">- **Schritt 1** - Für jedes Training-Sample $x_i$ berechne die Distanz $d(x_i, x)$ zwischen $x_i$ und $x$.\n",
    ">- **Schritt 2** - Sortiere die Training-Samples $x_i$ in aufsteigender räumlicher Distanz zu $x$.\n",
    ">- **Schritt 3** - Die $k$ räumlich nächsten Training-Samples werden als die k Nearest-Neighbors von $x$ bezeichnet.\n",
    ">- **Schritt 4** - Die Klassifikation von $x$ erfolgt anhand der Klassenverteilung der k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZzDrwGXt8rm"
   },
   "source": [
    "### 3.1. Hyperparameter Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Mrlx5MFt8rn"
   },
   "source": [
    "Um den **k Nearest-Neighbors** Algorithmus zu parametrisieren definieren ist es zunächst notwendig die entsprechenden Hyperparameter zu definieren. Hierbei handelt es sich um Parameter, welche nicht durch das Modell im Rahmen des Training gelernt werden können. Für das Training des **k Nearest-Neighbors** Klassifikators ist es notwendig zwei Hyperparameter vorab zu definieren:\n",
    "\n",
    ">1. Die Anzahl `k` der zu betrachtenden nächsten Nachbarn zur Klassifizierung eines Samples.\n",
    ">2. Das Distanzmass `d(u, v)` zur Berechnung der Abstände zwischen den einzelnen Samples `u` und `v`. \n",
    "\n",
    "\n",
    "In einem ersten Schritt definieren wir die Anzahl der Nachbarn `k`, die im Rahmen der Klassifizierung eines Samples berücksichtigt werden sollen. Wir setzen diesen Parameter `k=4` und berücksichtigen somit im Rahmen der Klassifikation jeweils die vier nächsten Nachbarn eines Samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqQ4MM3It8rn"
   },
   "outputs": [],
   "source": [
    "k_nearest_neighbors = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSc5L4XBt8ro"
   },
   "source": [
    "In einem zweiten Schritt definieren wir das Distanzmass. Im Seminar wurden zur Berechnung des Abstands zwischen einem Sample $u$ und den $k$-ächsten Nachbarn $v'_{j}$ in einem $n$-dimensonalen Merkmalsraum die nachfolgenden Distanzmasse vorgestellt:\n",
    "\n",
    "**Manhattan Distanz (L1-Norm):** $$ d(u, v)=\\|\\sum^k_{j=1}\\sum^n_{i=1}(u_{i} - v_{j,i})\\| $$\n",
    "\n",
    "**Euklidischer Distanz (L2-Norm):** $$ d(u, v)=\\sqrt{\\sum^k_{j=1}\\sum^n_{i=1}(u_{i} - v_{j,i})^2} $$\n",
    "\n",
    "wobei der Index $j$ die Anzahl der $k$-Nächsten Nachbarn und der Index $i$ das $i$-te Merkmal eines einzelnen Samples $u_j$ bzw. $v_j$ bezeichnet. Nachfolgend verwenden wir die euklidische Distanz als Distanzmetrik des zu trainierenden **k Nearest-Neighbors** Klassifikators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqGtCmjZt8ro"
   },
   "outputs": [],
   "source": [
    "distance_metric = 'euclidean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Definition der Hyperparameter initialisieren nun den **k Nearest-Neighbors** Algorithmus der [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN4KdNpwt8rq"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_nearest_neighbors, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5NV8Pect8rr"
   },
   "source": [
    "In einem nächsten Schritt, trainieren wir den Klassifikator auf Grundlage des Trainingsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4vhFkogt8rr"
   },
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfghQDgpt8rt"
   },
   "source": [
    "Nach erfolgreichem Training, verwenden wir das trainierte Modell um die Klassenlabel des ungesehenen Evaluationsdatens zu bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIDL-PPYt8rt"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTOBjotzt8r0"
   },
   "source": [
    "Werfen wir nun einen Blick auf die vorhergesagten Klassenlabels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "5zbDPKsrt8r0",
    "outputId": "35c71468-b08c-4e1e-ef40-2ee3be262f9b"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jO8PBi_dt8r6"
   },
   "source": [
    "Abschliessend vergleichen wir die vorhergesagten Klassenlabels mit den tatsächlichen **ground-truth** Klassenlabels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "pD-xHgePt8r6",
    "outputId": "f6d87beb-1942-4cac-db45-06a901c19cde"
   },
   "outputs": [],
   "source": [
    "y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. k Nearest-Neighbor (kNN) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXcfnX7ut8qH"
   },
   "source": [
    "In einem nächsten Schritt möchten wir nun die Güte des erlernten Modell's auch quantitiv zu evaluieren. Hierzu berechnen wir in die **Accuracy** des trainierten Modells auf Grundlage des Evaluationsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "JUjNPSw4t8qH",
    "outputId": "f9a61e9f-e236-4ec2-eb2e-fc990b198c73"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluation Accuracy, k=4: {} % \".format(metrics.accuracy_score(y_eval, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAR7qFaht8qJ"
   },
   "source": [
    "Darüber hinaus bestimmen wir auch die absolute Anzahl falsch klassifizierter Samples der Evaluationsdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7s8UEK8Vt8qJ",
    "outputId": "9d12ebc3-17ba-4ac9-ab8a-5d17ed2c0960"
   },
   "outputs": [],
   "source": [
    "print(\"Number of mislabeled points out of a total {} points: {}\".format(x_eval.shape[0], np.sum(y_eval != y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Confusion Matrix Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_xAgsV6t8qL"
   },
   "source": [
    "Für die genaue Beurteilung eines Modells wird im Kontext der statistischen Klassifikation oftmals eine sog. **Confusion Matrix** (Fehlermatrix) erstellt. Hierbei handelt es sich um eine Darstellung, welche die Performance eines Klassifikators über die unterschiedlichen Klassen visualisiert. In den Zeilen der Matrix werden für die Evaluationsdaten die Vorhersagen des Modells abgetragen. In den Spalten die tatsächlichen bzw. **Ground-Truth** Labels der Evaluationsdaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sv_p7Z_3t8qL"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"./confusion_matrix.png\">\n",
    "\n",
    "(Quelle: https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jRIduF8t8qM"
   },
   "source": [
    "Nachfolgend berechnen wir die **Confusion Matrix** unseres aktuellen **k Nearest-Neighbors** Modells mit den beiden Hyperparametern **k=4** und **Euklidischer-Distanz** auf Grundlage des Evaluationsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjLxhnrOt8qO"
   },
   "outputs": [],
   "source": [
    "# determine the prediction confusion matrix\n",
    "mat = confusion_matrix(y_eval, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAtUqq_vt8qR"
   },
   "source": [
    "Auch möchten wir die **Confusion Matrix** in einem nächsten Schritt und zu besseren Interpretation visualisueren: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "K-_WFNpVt8qS",
    "outputId": "50407636-f3b7-4b26-caaf-72698b1efb63"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plot confusion matrix heatmap\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='GnBu', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "\n",
    "# add plot axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]')\n",
    "\n",
    "# add plot title\n",
    "plt.title('Confusion Matrix - 4 Nearest-Neighbors', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Matrix ist zu entnehmen, dass es dem Modell nicht gelingt die beiden Klassen `virginica` und `versicolor` in allen Fällen fehlerfrei zu unterscheiden. Erinnern wir uns daran, dass wir im Rahmen des Seminars verschiedene Evaluationsmetriken z.B. **Präzision** und **Recall** zur Beurteilung der Qualität eines Modell's kennengelernt haben. Beide Metriken lassen sich nun aus der erstellten **Confusion Matrix** ableiten: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Die **Precision**, formal definiert als Precision $=\\frac{TP}{TP + FP}$, bezeichnet die Wahrscheinlichkeit, dass ein erhaltenes Dokument relevant ist.\n",
    ">- Der **Recall**, formal definiert als Recall $=\\frac{TP}{TP + FN}$, bezeichnet die Wahrscheinlichkeit das ein relevantes Dokument erhalten wurde.\n",
    ">- Der **F1-Score**, formal definiert als F1-Score $= 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$, ist das harmonische Mittel aus beiden vorhergehenden Metriken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Real-World Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZtOsS5ft8qY"
   },
   "source": [
    "Abschliessend möchten wir nun zwei **real-world** Iris Beispiele anhand unseres Modells klassifizieren.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 200px; height: auto\" src=\"./iris_sample_1.png\">\n",
    "\n",
    "(Quelle: https://de.wikipedia.org/wiki/Schwertlilien)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste **Iris Beobachtung** $x^{1}$ (siehe oben) weist die folgenden (normalisierten) Featurewerte auf: $x^{1} = \\{x_{1}=5.8, x_{2}=3.5, x_{3}=1.5, x_{4}=0.2\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init features of first iris flower observation \n",
    "sepal_length = 5.8 \n",
    "sepal_width  = 3.5\n",
    "petal_length = 1.5\n",
    "petal_width  = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwendung unseres Modells auf den Featurevektor von $x^1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "E3kPaqtKt8qY",
    "outputId": "d3343c51-20f2-4871-a108-ab6e646d7c8f"
   },
   "outputs": [],
   "source": [
    "# determine class label prediction of the first unknown observation\n",
    "class_prediction_sample_1 = knn.predict([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "\n",
    "# convert predicted class label to class name\n",
    "print(iris.target_names[class_prediction_sample_1[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 200px; height: auto\" src=\"./iris_sample_2.png\">\n",
    "\n",
    "(Quelle: https://de.wikipedia.org/wiki/Schwertlilien)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zweite **Iris Beobachtung** $x^{2}$ (siehe oben) weist die folgenden (normalisierten) Featurewerte auf: $x^{2} = \\{x_{1}=7.8, x_{2}=2.3, x_{3}=6.4, x_{4}=2.5\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init features of first iris flower observation \n",
    "sepal_length = 7.8 \n",
    "sepal_width  = 2.3\n",
    "petal_length = 6.4\n",
    "petal_width  = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwendung unseres Modells auf den Featurevektor von $x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "RI0efIyst8qb",
    "outputId": "2e08aa8e-9868-4831-f494-d129c65d4dc4"
   },
   "outputs": [],
   "source": [
    "# determine class label prediction of the second unknown observation\n",
    "class_prediction_sample_2 = knn.predict([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "\n",
    "# convert predicted class label to class name\n",
    "print(iris.target_names[class_prediction_sample_2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. k Nearest-Neighbor (kNN) Hyperparameter Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Hyperparameter Parameter Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNIUFJvkt8sF"
   },
   "source": [
    "Berücksichtigen der jeweils `k=8`nächsten Nachbarn eines Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSMgh-6Nt8sF"
   },
   "outputs": [],
   "source": [
    "k_nearest_neighbors = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5bS5N7gt8sH"
   },
   "source": [
    "Initialisierung des **k Nearest-Neighbors** Algorithmus der [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qHX0QRIt8sI"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_nearest_neighbors, metric=distance_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dEKmgmstt8sL"
   },
   "source": [
    "Training des Klassifikators auf Grundlage des Trainingsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1eqyDxyt8sL"
   },
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1JcOiVKt8sM"
   },
   "source": [
    "Nach erfolgreichem Training, verwenden wir das trainierte Modell um die Klassenlabels des ungesehenen Evaluationsdatens zu bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCPH0m2xt8sM"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvEEgKfzt8sN"
   },
   "source": [
    "Berchnung der **Accuracy** des trainierten Modells auf Grundlage des Evaluationsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Hv7zgswIt8sO",
    "outputId": "35130ea5-f27d-499b-e516-55954f1fdb6e"
   },
   "outputs": [],
   "source": [
    "print('Evaluation Accuracy, k=8: {} %'.format(metrics.accuracy_score(y_eval, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4u2VufLt8sP"
   },
   "source": [
    "Ermittlung und Visualisierung der **Konfusionsmatrix** der einzelnen Vorhersagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOBriWR-t8sP"
   },
   "outputs": [],
   "source": [
    "# determine the prediction confusion matrix\n",
    "mat = confusion_matrix(y_eval, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Rf40sz6t8sR"
   },
   "source": [
    "Visualisierung der **Confusion Matrix** des **k=8 Nearest-Neighbor** modells auf Grundlage des Evaluationsdatensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "LE_7IAbOt8sR",
    "outputId": "777a0aad-74b2-4d54-9bb1-9f6619acfa83"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plot confusion matrix heatmap\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='GnBu', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "\n",
    "# add plot axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]')\n",
    "\n",
    "# add plot title\n",
    "plt.title('8-NN Confusion Matrix, k=8', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermittlung der Evaluationsmetriken **Präzision** und **Recall** zur Beurteilung der Qualität eines Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "BiGJMg79t8sW",
    "outputId": "c5218d6d-9c5a-4401-f50f-cf330db9cc08"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXwgts9Yt8sY"
   },
   "source": [
    "### 5.2 Hyperparameter Parameter Grid-Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nV_vgPzDt8sZ"
   },
   "source": [
    "Bislang haben wir den auf dem euklidischen Abstand basierenden k Nearest-Neighbor Algorithmus lediglich für zwei verschiedene Werte von $k=4$ und $k=8$ untersucht. Es stellt sich jedoch die Frage, ob wir einen Wert für k finden können, der in einer noch höheren Accuracy resultiert. \n",
    "\n",
    "In einem nächsten Schritt untersuchen wir deshalb die Performance des Algorithmus eines umfangreichen Intervalls von verschiedenen $k$-Werten und vergleichen die jeweils erhaltene Accuracy. Um eine solchen **Grid-Search** durchführen zu können definieren zunächst einen Array mit den verschiedenen zu evaluierenden $k$-Werten zwischen $k=1, ..., 30$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6cblKEXt8sZ"
   },
   "outputs": [],
   "source": [
    "# try k=1 through k=50 to be evaluated\n",
    "k_range = range(1, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oLJdsWDt8sb"
   },
   "source": [
    "In einem nächsten Schritt definieren wir eine Schleife, welche über die verschiedenen k-Werte iteriert. In jeder Iteration wird für den aktuellen k-Wert ein Modelltraining (unter Verwendung der Trainingsdaten) und die entsprechende Evaluation (unter Verwendung der Evaluationsdaten) durchgeführt. Nach erfolger Durchführung speichern die für den $k$-Wert zu erzielende Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Q0TwLLyt8sb"
   },
   "outputs": [],
   "source": [
    "# init the distinct accuracy scores obtained on the evaluation data\n",
    "eval_accuracy_scores = []\n",
    "\n",
    "# iterate over the distinct k values\n",
    "for k in k_range:\n",
    "    \n",
    "    # init the k-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "    \n",
    "    # train the k-NN classifer on the training data\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    # evaluate the k-NN classifier on the training data\n",
    "    y_train_pred = knn.predict(x_train)\n",
    "    \n",
    "    # evaluate the k-NN classifier on the evaluation data\n",
    "    y_eval_pred = knn.predict(x_eval)\n",
    "    \n",
    "    # collect the classification accuracy of the current k on the evaluation data\n",
    "    eval_accuracy_scores.append(metrics.accuracy_score(y_eval, y_eval_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZIpTs4ut8sd"
   },
   "source": [
    "Visualisierung der Accuracy für die verschiedenen $k$-Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "ng4ljiGLt8sd",
    "outputId": "fbccbccc-0a3c-4b10-c379-c648f977f772"
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot the classification accuracy of distinct k's\n",
    "ax.plot(range(1, len(eval_accuracy_scores)+1), eval_accuracy_scores, color='cornflowerblue', marker='o')\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# add axis range and legends\n",
    "ax.set_xlabel(\"[$k$-Nearest-Neighbors]\", fontsize=10)\n",
    "ax.set_ylabel(\"[% classification accuracy]\", fontsize=10)\n",
    "\n",
    "# add plot title\n",
    "ax.set_title('k-NN Classification Accuracy', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqwcEsTlt8qg"
   },
   "source": [
    "## Lab Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XamqRlpot8sg"
   },
   "source": [
    "Im Ihr wissen zu vertiefen empfehlen wir, die nachfolgenden Übungen zu bearbeiten:\n",
    "\n",
    "**1. Trainieren, Evaluieren und Visualisieren Sie die Accuracy der k=1,...,50 Nearest-Neighbor Modelle.**\n",
    "\n",
    "> Schreiben Sie eine Python-Schleife, die die Vorhersagegenauigkeit aller k Nearest-Neighbor Parametrisierungen im Bereich von k=1,...,50 ermittelt. Sammeln und visualisieren Sie die Vorhersagegenauigkeit jedes Modells und **vergleichen Sie die Ergebnisse**. Stellen Sie die Vorhersagegenauigkeit für jedes der oben genannten Modelle grafisch dar. Das Diagramm sollte die verschiedenen Werte von k auf der x-Achse und die entsprechende Modellvorhersagegenauigkeit auf der y-Achse anzeigen. Welches Verhalten in Bezug auf die Vorhersagegenauigkeit kann mit zunehmendem k beobachtet werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMjmHfA6t8sg"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1vLeQMMt8sj"
   },
   "source": [
    "**2. Trainieren, Evaluieren und Visualisieren Sie die Accuracy der k=1,...,50 Nearest-Neighbor Modelle ohne Skalierung der Features.**\n",
    "\n",
    "> Schreiben Sie eine Python-Schleife, die die Vorhersagegenauigkeit aller k Nearest-Neighbor Parametrisierungen im Bereich von k=1,...,50 ermittelt. Verwenden Sie für das Modelltraining diesmal die **nicht skalierten Features**. Sammeln und visualisieren Sie die Vorhersagegenauigkeit jedes Modells und vergleichen Sie die Ergebnisse. Stellen Sie die Vorhersagegenauigkeit für jedes der oben genannten Modelle grafisch dar. Das Diagramm sollte die verschiedenen Werte von k auf der x-Achse und die entsprechende Modellvorhersagegenauigkeit auf der y-Achse anzeigen. Wie verhalten sich die Ergebnisse im Vergleich zu Aufgabe 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikdzkjK0t8sk"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Lwqs0XLt8sr"
   },
   "source": [
    "**3. Trainieren, Evaluieren und Visualisieren Sie die Accuracy der k=1,...,50 Nearest-Neighbor Modelle unter Verwendung der Manhattan Distanz.**\n",
    "\n",
    "> Schreiben Sie eine Python-Schleife, die die Vorhersagegenauigkeit aller k Nearest-Neighbor Parametrisierungen im Bereich von k=1,...,50 ermittelt. Verwenden Sie für das Modelltraining diesmal die **Manhattan Distanz** anstatt der Euklidischen Distanz. Sammeln und visualisieren Sie die Vorhersagegenauigkeit jedes Modells und vergleichen Sie die Ergebnisse. Stellen Sie die Vorhersagegenauigkeit für jedes der oben genannten Modelle grafisch dar. Das Diagramm sollte die verschiedenen Werte von k auf der x-Achse und die entsprechende Modellvorhersagegenauigkeit auf der y-Achse anzeigen. Wie verhalten sich die Ergebnisse im Vergleich zu Aufgabe 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIUran5pt8ss"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n94u0rxat8su"
   },
   "source": [
    "## Lab Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCOEZj-it8sv"
   },
   "source": [
    "Dieses Notebook umfasste eine schrittweise Einführung in einige grundlegende Konzepte eines **Supervised Machine Learning** Prozesses in Jupyter Notebooks. Die vorgestellten Code Beispiele und die Übungen können als Ausgangspunkt für komplexere und Ihre massgeschneiderten Analysen dienen."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eGwNwDKEt8lG",
    "D0Jnx-Ljt8lK",
    "CZaa0qAnt8lY",
    "mMSfpCPvt8l4",
    "n94u0rxat8su"
   ],
   "name": "lab_02.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
